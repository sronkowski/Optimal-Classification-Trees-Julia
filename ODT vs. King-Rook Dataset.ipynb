{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-04 01:27:32.245"
     ]
    }
   ],
   "source": [
    "using Dates\n",
    "print(Dates.today(), \" \", Dates.Time(Dates.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Decision Trees - King-Rook Dataset\n",
    "\n",
    "## Stephen Ronkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/sronk/Downloads/Machine_Learning_MSCA_31009/Homework/data/\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load needed modules\n",
    "using JuMP\n",
    "using CSV\n",
    "using DecisionTree\n",
    "using StatsBase\n",
    "using DataFrames\n",
    "using MLDataUtils\n",
    "\n",
    "#note - Gurobi is not FOSS - licensing required!\n",
    "#this model can be solved using any MIO solver compatible with JuMP\n",
    "#see http://www.juliaopt.org/JuMP.jl/v0.20.0/installation/#Getting-Solvers-1\n",
    "using Gurobi\n",
    "\n",
    "#data path declaration\n",
    "FILEDIR = \"/home/sronk/Downloads/Machine_Learning_MSCA_31009/Homework/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion & Processing\n",
    "\n",
    "This dataset is available [here](https://archive.ics.uci.edu/ml/machine-learning-databases/chess/king-rook-vs-king-pawn/).  Since this dataset is entirely in text, I will first transform the text into dummy-coded variables, again preserving the $0 \\leq x_i \\leq 1$ requirement of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>col1</th><th>col2</th><th>col3</th><th>col4</th><th>col5</th><th>col6</th><th>col7</th><th>col8</th><th>col9</th><th>col10</th></tr><tr><th></th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th></tr></thead><tbody><p>3,196 rows × 37 columns (omitted printing of 27 columns)</p><tr><th>1</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>2</th><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>3</th><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td></tr><tr><th>4</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>5</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>6</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>7</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>8</th><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>9</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>10</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td></tr><tr><th>11</th><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td></tr><tr><th>12</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>13</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>14</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>15</th><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>16</th><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>17</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>18</th><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td></tr><tr><th>19</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>20</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>21</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>22</th><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>23</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>24</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>25</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>26</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td></tr><tr><th>27</th><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td><td>t</td><td>f</td><td>f</td><td>f</td></tr><tr><th>28</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>t</td><td>f</td></tr><tr><th>29</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>30</th><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td><td>f</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccc}\n",
       "\t& col1 & col2 & col3 & col4 & col5 & col6 & col7 & col8 & col9 & col10 & \\\\\n",
       "\t\\hline\n",
       "\t& String & String & String & String & String & String & String & String & String & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t2 & f & f & f & f & t & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t3 & f & f & f & f & t & f & t & f & f & f & $\\dots$ \\\\\n",
       "\t4 & f & f & f & f & f & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t5 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t6 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t7 & f & f & f & f & f & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t8 & f & f & f & f & t & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t9 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t10 & f & f & f & f & f & f & t & f & f & f & $\\dots$ \\\\\n",
       "\t11 & f & f & f & f & t & f & t & f & f & f & $\\dots$ \\\\\n",
       "\t12 & f & f & f & f & f & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t13 & f & f & f & f & f & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t14 & f & f & f & f & f & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t15 & f & f & f & f & t & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t16 & f & f & f & f & t & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t17 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t18 & f & f & f & f & t & f & t & f & f & f & $\\dots$ \\\\\n",
       "\t19 & f & f & f & f & f & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t20 & f & f & f & f & f & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t21 & f & f & f & f & f & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t22 & f & f & f & f & t & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t23 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t24 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t25 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t26 & f & f & f & f & f & f & t & f & f & f & $\\dots$ \\\\\n",
       "\t27 & f & f & f & f & t & f & t & f & f & f & $\\dots$ \\\\\n",
       "\t28 & f & f & f & f & f & f & f & f & t & f & $\\dots$ \\\\\n",
       "\t29 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t30 & f & f & f & f & f & f & f & f & f & f & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3196×37 DataFrame. Omitted printing of 29 columns\n",
       "│ Row  │ col1   │ col2   │ col3   │ col4   │ col5   │ col6   │ col7   │ col8   │\n",
       "│      │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │\n",
       "├──────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
       "│ 1    │ f      │ f      │ f      │ f      │ f      │ f      │ f      │ f      │\n",
       "│ 2    │ f      │ f      │ f      │ f      │ t      │ f      │ f      │ f      │\n",
       "│ 3    │ f      │ f      │ f      │ f      │ t      │ f      │ t      │ f      │\n",
       "│ 4    │ f      │ f      │ f      │ f      │ f      │ f      │ f      │ f      │\n",
       "│ 5    │ f      │ f      │ f      │ f      │ f      │ f      │ f      │ f      │\n",
       "│ 6    │ f      │ f      │ f      │ f      │ f      │ f      │ f      │ f      │\n",
       "│ 7    │ f      │ f      │ f      │ f      │ f      │ f      │ f      │ f      │\n",
       "│ 8    │ f      │ f      │ f      │ f      │ t      │ f      │ f      │ f      │\n",
       "│ 9    │ f      │ f      │ f      │ f      │ f      │ f      │ f      │ f      │\n",
       "│ 10   │ f      │ f      │ f      │ f      │ f      │ f      │ t      │ f      │\n",
       "⋮\n",
       "│ 3186 │ f      │ f      │ f      │ f      │ t      │ f      │ t      │ f      │\n",
       "│ 3187 │ t      │ f      │ f      │ f      │ t      │ f      │ t      │ f      │\n",
       "│ 3188 │ f      │ f      │ f      │ t      │ f      │ f      │ t      │ t      │\n",
       "│ 3189 │ f      │ f      │ f      │ t      │ f      │ f      │ t      │ t      │\n",
       "│ 3190 │ f      │ f      │ f      │ t      │ f      │ f      │ t      │ t      │\n",
       "│ 3191 │ f      │ f      │ f      │ f      │ f      │ f      │ t      │ f      │\n",
       "│ 3192 │ t      │ f      │ f      │ f      │ f      │ f      │ t      │ f      │\n",
       "│ 3193 │ t      │ f      │ f      │ f      │ f      │ f      │ t      │ f      │\n",
       "│ 3194 │ t      │ f      │ f      │ f      │ f      │ f      │ t      │ f      │\n",
       "│ 3195 │ t      │ f      │ t      │ f      │ f      │ f      │ t      │ f      │\n",
       "│ 3196 │ t      │ f      │ t      │ f      │ f      │ f      │ t      │ f      │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate header\n",
    "num_header = collect(1:37)\n",
    "my_header = [\"col\"*string(i) for i in num_header]\n",
    "\n",
    "#load king-rook file\n",
    "csv = CSV.File(FILEDIR * \"kr-vs-kp.data\", header = my_header)\n",
    "df = DataFrame(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{String,1}:\n",
       " \"f\"  \n",
       " \"l\"  \n",
       " \"n\"  \n",
       " \"t\"  \n",
       " \"won\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review current data formatting\n",
    "unique(df[1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize empty array\n",
    "feature_array = zeros(size(df))\n",
    "\n",
    "#iterate over dataframe, fill in new array with dummy-coded values\n",
    "for row in 1:size(df)[1]\n",
    "    for col in 1:size(df)[2]   \n",
    "        if df[row,col] == \"f\"\n",
    "            feature_array[row,col] = 0.2\n",
    "        elseif df[row,col] == \"l\"\n",
    "            feature_array[row,col] = 0.4\n",
    "        elseif df[row,col] == \"n\"\n",
    "            feature_array[row,col] = 0.6\n",
    "        elseif df[row,col] == \"t\"\n",
    "            feature_array[row,col] = 0.8\n",
    "            #these two are for the y variable\n",
    "        elseif df[row,col] == \"won\"\n",
    "            feature_array[row,col] = 1\n",
    "        elseif df[row,col] == \"nowin\"\n",
    "            feature_array[row,col] = 2\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3196×37 Array{Float64,2}:\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  …  0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.8  0.2  0.2  0.2     0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.8  0.2  0.8  0.2     0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2     0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2     0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  …  0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2     0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.8  0.2  0.2  0.2     0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2     0.8  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.8  0.2     0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.8  0.2  0.8  0.2  …  0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2     0.2  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2     0.8  0.2  0.2  0.8  0.8  0.6  1.0\n",
       " ⋮                        ⋮              ⋱  ⋮                        ⋮       \n",
       " 0.8  0.2  0.2  0.2  0.8  0.2  0.8  0.2     0.2  0.8  0.2  0.8  0.2  0.6  2.0\n",
       " 0.2  0.2  0.2  0.2  0.8  0.2  0.8  0.2  …  0.2  0.8  0.2  0.8  0.2  0.6  2.0\n",
       " 0.8  0.2  0.2  0.2  0.8  0.2  0.8  0.2     0.2  0.8  0.2  0.8  0.2  0.6  2.0\n",
       " 0.2  0.2  0.2  0.8  0.2  0.2  0.8  0.8     0.2  0.8  0.2  0.2  0.2  0.6  2.0\n",
       " 0.2  0.2  0.2  0.8  0.2  0.2  0.8  0.8     0.2  0.8  0.2  0.8  0.2  0.6  2.0\n",
       " 0.2  0.2  0.2  0.8  0.2  0.2  0.8  0.8     0.2  0.8  0.2  0.2  0.2  0.6  2.0\n",
       " 0.2  0.2  0.2  0.2  0.2  0.2  0.8  0.2  …  0.2  0.8  0.2  0.8  0.2  0.6  2.0\n",
       " 0.8  0.2  0.2  0.2  0.2  0.2  0.8  0.2     0.2  0.8  0.2  0.8  0.2  0.6  2.0\n",
       " 0.8  0.2  0.2  0.2  0.2  0.2  0.8  0.2     0.2  0.8  0.2  0.8  0.2  0.6  2.0\n",
       " 0.8  0.2  0.2  0.2  0.2  0.2  0.8  0.2     0.2  0.8  0.2  0.8  0.2  0.6  2.0\n",
       " 0.8  0.2  0.8  0.2  0.2  0.2  0.8  0.2     0.2  0.8  0.2  0.2  0.2  0.6  2.0\n",
       " 0.8  0.2  0.8  0.2  0.2  0.2  0.8  0.2  …  0.2  0.8  0.2  0.2  0.2  0.6  2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review loop output\n",
    "feature_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " ⋮\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle observations and split into train/test\n",
    "feature_array = shuffleobs(feature_array, obsdim = 1)\n",
    "feature_array = getobs(feature_array)\n",
    "train, test = splitobs(feature_array, at = 0.7, obsdim = 1)\n",
    "\n",
    "#extract features from input matrix, unit transform\n",
    "features = train[:,1:36]\n",
    "\n",
    "#extract labels from input matrix\n",
    "labels = train[:,37]\n",
    "labels = convert(Array{Int64}, labels)\n",
    "\n",
    "#extract features from input matrix, unit transform\n",
    "test_features = test[:,1:36]\n",
    "\n",
    "#extract labels from input matrix\n",
    "test_labels = test[:,37]\n",
    "test_labels = convert(Array{Int64}, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels must be one-indexed for the model to function properly, so I confirm as much here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Int64,1}:\n",
       " 1\n",
       " 2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm that labels are 1-indexed\n",
    "#labels = labels .- 2\n",
    "unique(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sake of comparison, I will now fit a simple Decision Tree over this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 21, Threshold 0.5\n",
      "L-> Feature 10, Threshold 0.5\n",
      "    L-> 1 : 720/1283\n",
      "    R-> 2 : 524/524\n",
      "R-> 1 : 430/430\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(max_depth=2)\n",
    "DecisionTree.fit!(dt_model, features, labels)\n",
    "print_tree(dt_model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation\n",
    "\n",
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "makeYMatrix (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function findEpsilon(array)\n",
    "    #capture array length for iteration\n",
    "    array_len = size(array, 1)\n",
    "    \n",
    "    #sort array\n",
    "    sorted_array = sort(array, rev = true)\n",
    "    \n",
    "    #initialize epsilon with arbitrarily large value\n",
    "    epsilon = 1e5\n",
    "    \n",
    "    #iterate through consecutive values to find smallest non-zero difference\n",
    "    for i in 2:(array_len - 1)\n",
    "        diff = abs(sorted_array[i-1] - sorted_array[i])\n",
    "        if 0 < diff < epsilon\n",
    "            epsilon = diff\n",
    "        end\n",
    "    end\n",
    "    #output smallest non-zero difference\n",
    "    return epsilon\n",
    "end\n",
    "\n",
    "function epsilonArrayGenerator(matrix)\n",
    "    #capture number of features in dataset, i.e. the number of columns\n",
    "    matrix_rows = size(matrix, 2)\n",
    "    \n",
    "    #initialize output DataFrame\n",
    "    epsilon_array = Vector{Float64}(undef,matrix_rows)\n",
    "    \n",
    "    #iterate findEpsilon function over each column\n",
    "    for col in 1:matrix_rows\n",
    "        epsilon_array[col] = findEpsilon(matrix[:,col])\n",
    "    end\n",
    "    return epsilon_array\n",
    "end\n",
    "\n",
    "function makeAncestorDict(max_nodes)\n",
    "    #initialize empty dictionaries\n",
    "    A_left = Dict{Int64, Vector{Int64}}()\n",
    "    A_right = Dict{Int64, Vector{Int64}}()\n",
    "    #A_left[1] = [1]\n",
    "    #A_right[1] = [1]\n",
    "    #generate keys with empty array values for each node\n",
    "    for i in 1:max_nodes\n",
    "        A_left[i] = []\n",
    "        A_right[i] = []\n",
    "    end\n",
    "    #loop over all nodes, copying the left and right ancestors of the node above it\n",
    "    for i in 2:max_nodes\n",
    "        left_ancestors = copy(A_left[i ÷ 2])\n",
    "        right_ancestors = copy(A_right[i ÷ 2])\n",
    "        direct_ancestor = i ÷ 2\n",
    "        A_left[i] = left_ancestors\n",
    "        A_right[i] = right_ancestors\n",
    "        #add a left ancestor to even nodes\n",
    "        if i/2 == i ÷ 2\n",
    "            append!(left_ancestors, direct_ancestor)\n",
    "            A_left[i] = left_ancestors\n",
    "        #add a right ancestor to odd nodes\n",
    "        else\n",
    "            append!(right_ancestors, direct_ancestor)\n",
    "            A_right[i] = right_ancestors\n",
    "        end\n",
    "    end\n",
    "    return A_left, A_right\n",
    "end\n",
    "\n",
    "function makeYMatrix(labels)    \n",
    "    #extract dimensions for Y from label array\n",
    "    num_labels = length(unique(labels))\n",
    "    len_df = length(labels)\n",
    "    \n",
    "    #initialize empty matrix\n",
    "    Y = zeros(len_df, num_labels)\n",
    "    \n",
    "    #set all values to -1 - this will apply a penalty to incorrect predictions\n",
    "    Y = Y  .- 1\n",
    "    \n",
    "    #iterate n over each column, setting Y[n,k] = 1 when the label for x[i] = k\n",
    "    for k in 1:num_labels\n",
    "        for n in 1:len_df\n",
    "            if labels[n] == k\n",
    "                Y[n,k] = 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return Y\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration of Model Constants\n",
    "\n",
    "In a given model space for this optimization function, there are a variety of constants that are either set by the user as a hyperparameter or generated dynamically based on those hyperparameters or the input data set.\n",
    "\n",
    "I will begin by establishing the numerical values related to the structure of the tree, $D, N_{min}, t$, and $\\alpha$  Here, $D$ is the maximum depth of the Tree, $N_{min}$ is the minimum number of samples needed to compose a leaf node, and $t$ is the total possible number of nodes in a tree.\n",
    "\n",
    "The last of these user-declared variables, $\\alpha$, is a complexity parameter that penalizes overly complex tree structures. (elaborate here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set maximum depth of tree as a constant\n",
    "max_depth = 2\n",
    "\n",
    "#minimum number of values for a given leaf node\n",
    "leaf_n_min = 20\n",
    "\n",
    "#declare complexity parameter alpha\n",
    "alpha = 0.1\n",
    "\n",
    "#find total number of nodes in tree using max_depth, t\n",
    "max_nodes = 2^(max_depth+1) - 1\n",
    "\n",
    "#initialize branch and leaf node arrays - first, find the split point between branch and leaf indices\n",
    "#split point is by definition the number of nodes integer divided by two\n",
    "leaf_branch_split = max_nodes ÷ 2\n",
    "\n",
    "#total number of branches\n",
    "t_b = collect(1:leaf_branch_split)\n",
    "\n",
    "#total number of leaves\n",
    "t_l = collect(leaf_branch_split+1:max_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will establish the model constants that are derived from the input dataset: $n, k$, and $p$.  Here, $n$ represents the number of samples within the dataset, $p$ represents the number of features in the dataset, and $k$ represents the total number of labels.\n",
    "\n",
    "I will also establish the constant $\\hat{L}$. This constant represents the \"naive\" prediction, namely, that every value in the dataset is a member of the most common class.  This value is then used within the optimization function (elaborate here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5140813589628968"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pull number of samples in dataset, n\n",
    "num_samples = size(features, 1)\n",
    "\n",
    "#find total number of columns in the feature space, p\n",
    "num_features = size(features, 2)\n",
    "\n",
    "#find total number of labels, k\n",
    "num_labels = length(unique(labels))\n",
    "\n",
    "#create dictionary with prediction labels as key and count of each prediction as value\n",
    "output_count = countmap(labels)\n",
    "\n",
    "#extract the count for most common label to form l_hat, which is baseline accuracy rate\n",
    "l_hat = sort(collect(output_count), by = tuple -> last(tuple), rev=true)[1,1][2]/length(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, I manually set $\\epsilon_j$ to $0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2237×2 Array{Float64,2}:\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       " -1.0   1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       " -1.0   1.0\n",
       "  ⋮        \n",
       "  1.0  -1.0\n",
       " -1.0   1.0\n",
       " -1.0   1.0\n",
       "  1.0  -1.0\n",
       " -1.0   1.0\n",
       " -1.0   1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       "  1.0  -1.0\n",
       " -1.0   1.0\n",
       " -1.0   1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build ancestor dictionaries using definitions given above\n",
    "A_left, A_right = makeAncestorDict(max_nodes)\n",
    "\n",
    "#generate the epsilon array as defined earlier\n",
    "#epsilon_array = epsilonArrayGenerator(features)\n",
    "epsilon_array = zeros(36) .+ 0.01\n",
    "\n",
    "#M_1 constant - defined as 1 plus the largest epsilon value\n",
    "M_1 = 1 + maximum(epsilon_array)\n",
    "\n",
    "#M constant - set equal to number of samples as rule of thumb\n",
    "M = length(labels)\n",
    "\n",
    "#generate Y matrix\n",
    "Y = makeYMatrix(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable and Constraint Declarations\n",
    "\n",
    "With the constants now fixed, the model itself can now be built inside JuMP.  The first step is to declare the model itself, at which point I also limit the runtime of the optimizer to two hours.\n",
    "\n",
    "From there, I will begin building the model by establishing the variables that model the structure of the tree itself.  The first of these are $b$, an array that captures the decision point for each node that applies a split, and $a_{j,t}$, a hot-coded matrix that indicates when feature $j$ is used to split at node $t$. Additionally, we initialize array $d$, which is hot-coded to indicate when a given branch is active (i.e. a split is applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n"
     ]
    }
   ],
   "source": [
    "#initialize model\n",
    "model = Model(with_optimizer(Gurobi.Optimizer, Presolve=0, OutputFlag=1, TimeLimit=14400))\n",
    "\n",
    "#b is the decision point for each branch node\n",
    "#s/t a.T*x < b at a given split \n",
    "@variable(model, b[i=t_b])\n",
    "\n",
    "#a is a hot-coded matrix that captures the variable being used to split at given branch node\n",
    "@variable(model, a[j = 1:num_features, t = 1:leaf_branch_split])\n",
    "\n",
    "#4 - establish binary constraint on a\n",
    "for j in 1:num_features\n",
    "    for t in t_b\n",
    "        @constraint(model, a[j,t] in MOI.ZeroOne())\n",
    "    end\n",
    "end\n",
    "\n",
    "#d is an indicator array equal to one when a split is applied at a given node\n",
    "@variable(model, d[1:leaf_branch_split])\n",
    "\n",
    "#constrain d to binary values\n",
    "for t in t_b\n",
    "    @constraint(model, d[t] in MOI.ZeroOne())\n",
    "end\n",
    "\n",
    "#2 - establish that row-wise sum of a must equal 1 for all rows - yes\n",
    "for t in t_b\n",
    "    #@constraint(model, sum(a[j,t] for j=1:num_features) == d[t])\n",
    "    @constraint(model, sum(a[j,t] for j=1:num_features) == d[t])\n",
    "    @constraint(model, sum(a[j,t] for j=1:num_features) == 1)\n",
    "end\n",
    "\n",
    "#3 - establish that b split point must be 0 <= b[i] <= d[i] - yes\n",
    "for t in t_b\n",
    "    @constraint(model, b[t] >= 0)\n",
    "    @constraint(model, d[t] >= b[t])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is possible that certain branches will not be needed to achieve an optimal solution, I will establish that only those nodes which have a split applied above them can also apply a split.  This constraint ensures that once the optimizer no longer needs to split along a given branch path (i.e. that a given branch has already achieved perfect purity) it will simply route the input features to a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5- constrain d s/t splits cannot be applied below a node that does not also split\n",
    "#this does not apply to d[1] since that is the parent node and must always split\n",
    "@constraint(model, d[1] == 1)\n",
    "\n",
    "for t in 2:leaf_branch_split\n",
    "    parent = t ÷ 2\n",
    "    @constraint(model, d[t] <= d[parent])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z is a hot-coded matrix captures which values are assigned to which node\n",
    "@variable(model, z[i = 1:num_samples, t = t_l])\n",
    "\n",
    "#constrain z to binary values {0,1}\n",
    "for i in 1:num_samples\n",
    "    for t in t_l\n",
    "        @constraint(model, z[i,t] in MOI.ZeroOne())\n",
    "    end\n",
    "end\n",
    "\n",
    "#l is a hot-coded array s/t l(t) = 1 when leaf node t contains any values \n",
    "@variable(model, l[t = t_l])\n",
    "\n",
    "#contrain l to binary values {0,1}\n",
    "for t in t_l\n",
    "    @constraint(model, l[t] in MOI.ZeroOne())\n",
    "end\n",
    "\n",
    "#6 - constrain predictions to only be fit into nodes containing points\n",
    "for i in 1:num_samples\n",
    "    for t in t_l\n",
    "        @constraint(model, z[i,t] <= l[t])\n",
    "    end\n",
    "end\n",
    "\n",
    "#7- constrain number of samples assigned to a given leaf by lower bound \n",
    "#s/t number of samples is always greater/equal to min leaf size constant\n",
    "for t in t_l\n",
    "    @constraint(model, sum(z[i,t] for i in 1:num_samples) >= leaf_n_min * l[t])\n",
    "end\n",
    "\n",
    "#8 - constrain each point in data set so it can only be assigned to one leaf node\n",
    "for i in 1:num_samples\n",
    "    @constraint(model, sum(z[i,t] for t in t_l) == 1)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the tree structure and variable spaces now established, I move on to the splitting constraints.  These constraints capture the \"path\" that leads to each leaf node.  For leaf node $t$, the left-hand path is taken at ancestor node(s) $A_{left}(t) = m$ when $A^T(x_i + \\epsilon) \\leq b(m)$, and the right-hand path is taken at ancestor node(s) $A_{right}(t) = m$ when $A^Tx_i \\geq b(m)$.\n",
    "\n",
    "(Note that equations 9-12 are intermediate steps that give the derivations below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13 - establish left split constraints\n",
    "for i in 1:num_samples  \n",
    "    for t in t_l\n",
    "        for m in A_left[t]\n",
    "            @constraint(model, transpose(a[:,m]) * (features[i,:] + epsilon_array) <= b[m] + M_1*(1 - z[i,t]))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "#14 - establish right split contraints\n",
    "for i in 1:num_samples\n",
    "    for t in t_l\n",
    "        for m in A_right[t]      \n",
    "            @constraint(model, transpose(a[:,m]) * features[i,:] >= b[m] - (1 - z[i,t]))\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the branch nodes now fully modelled, we turn to a series of variables that capture the $x_i$ features present within each node.  The first of these is $N_{k,t}$, which gives the total number of inputs with label $k$ in leaf node $t$.  Paired with this is $N_t$, which gives the sum total of inputs assigned to each leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_kt is the number of points with label k in leaf node t\n",
    "@variable(model, N_kt[i = 1:num_labels, j = t_l])\n",
    "\n",
    "#15 - establish values for N_kt[t]\n",
    "for k in 1:num_labels\n",
    "    for t in t_l\n",
    "        @constraint(model, N_kt[k,t] == 0.5 * sum((1 + Y[i,k])*z[i,t] for i = 1:num_samples))\n",
    "    end\n",
    "end\n",
    "\n",
    "#N_t is the total number of values in a leaf node t\n",
    "@variable(model, N_t[i = t_l])\n",
    "\n",
    "#16 - establish values for N_t[t] as sum of z[i,t] for each t\n",
    "for t in t_l\n",
    "    @constraint(model, N_t[t] == sum(z[i,t] for i = 1:num_samples))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with these variables, we capture the prediction made by each node in matrix $c_{k,t}$, which is hot-coded such that the prediction for leaf $t$ is $k$ when $c_{k,t} = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_kt is a matrix that holds the label count of each variable within a given leaf nodes\n",
    "@variable(model, c_kt[i = 1:num_labels, j = t_l])\n",
    "\n",
    "#constrain c_kt to binary values {0,1}\n",
    "for k in 1:num_labels\n",
    "    for t in t_l\n",
    "        @constraint(model, c_kt[k,t] in MOI.ZeroOne())\n",
    "    end\n",
    "end\n",
    "\n",
    "#18 - force prediction for each node with values\n",
    "for t in t_l\n",
    "    @constraint(model, l[t] == sum(c_kt[k,t] for k = 1:num_labels))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we define loss array $L_t$, which is derived by applying a penalty factor for each prediction not in the majority class present in leaf node $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L is the loss for a given leaf node t\n",
    "@variable(model, L[i = t_l])\n",
    "\n",
    "#20 - set loss function lower bound\n",
    "for k in 1:num_labels\n",
    "    for t in t_l\n",
    "        @constraint(model, L[t] >= N_t[t] - N_kt[k,t] - (M * (1 - c_kt[k,t])))\n",
    "    end\n",
    "end\n",
    "\n",
    "#21 - set loss function upper bound\n",
    "for k in 1:num_labels\n",
    "    for t in t_l\n",
    "        @constraint(model, L[t] <= N_t[t] - N_kt[k,t] + (M * c_kt[k,t]))\n",
    "    end\n",
    "end\n",
    "\n",
    "#22 - set all L values to be positive\n",
    "for t in t_l\n",
    "   @constraint(model, L[t] >= 0) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now set the objective function, which is to minimize loss relative to the complexity of the tree as measured by the number of active branch nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ 1.9452173913043478 L_{4} + 1.9452173913043478 L_{5} + 1.9452173913043478 L_{6} + 1.9452173913043478 L_{7} + 0.1 d_{1} + 0.1 d_{2} + 0.1 d_{3} $$"
      ],
      "text/plain": [
       "1.9452173913043478 L[4] + 1.9452173913043478 L[5] + 1.9452173913043478 L[6] + 1.9452173913043478 L[7] + 0.1 d[1] + 0.1 d[2] + 0.1 d[3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@objective(model, Min, (1/l_hat) * sum(L[t] for t in t_l)) + (alpha * sum(d[t] for t in t_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the objective function now established, we call the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Optimize a model with 29136 rows, 9090 columns and 729505 nonzeros\n",
      "Variable types: 19 continuous, 9071 integer (9071 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-02, 2e+03]\n",
      "  Objective range  [2e+00, 2e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 2e+03]\n",
      "Variable types: 7 continuous, 9083 integer (9071 binary)\n",
      "Found heuristic solution: objective 2114.4513043\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 3983 iterations, 0.59 seconds\n",
      "Total elapsed time = 6.50s\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0 1754 2114.45130    0.00000   100%     -   10s\n",
      "     0     0    0.00000    0 1770 2114.45130    0.00000   100%     -   11s\n",
      "     0     0    0.00000    0 1768 2114.45130    0.00000   100%     -   11s\n",
      "     0     0    0.00000    0 1762 2114.45130    0.00000   100%     -   16s\n",
      "     0     0    0.00000    0 1764 2114.45130    0.00000   100%     -   17s\n",
      "     0     0    0.00000    0 1762 2114.45130    0.00000   100%     -   21s\n",
      "     0     0    0.00000    0 1762 2114.45130    0.00000   100%     -   21s\n",
      "     0     0    0.00000    0 1597 2114.45130    0.00000   100%     -   34s\n",
      "     0     0    0.00000    0 1458 2114.45130    0.00000   100%     -   35s\n",
      "     0     0    0.00000    0  660 2114.45130    0.00000   100%     -   41s\n",
      "     0     0    0.00000    0  686 2114.45130    0.00000   100%     -   42s\n",
      "     0     0    0.00000    0  364 2114.45130    0.00000   100%     -   47s\n",
      "     0     0    0.00000    0  374 2114.45130    0.00000   100%     -   48s\n",
      "     0     0    0.00000    0  346 2114.45130    0.00000   100%     -   50s\n",
      "     0     0    0.00000    0  346 2114.45130    0.00000   100%     -   51s\n",
      "     0     2    0.00000    0  294 2114.45130    0.00000   100%     -   63s\n",
      "     1     4    0.00000    1 4132 2114.45130    0.00000   100% 11873   65s\n",
      "     3     8    0.00000    2 3163 2114.45130    0.00000   100%  6083   82s\n",
      "     7    12    0.00000    3 3143 2114.45130    0.00000   100%  3882   87s\n",
      "    15    19    0.00000    4 2964 2114.45130    0.00000   100%  2684   93s\n",
      "    19    17    0.00000    5 4486 2114.45130    0.00000   100%  2528   96s\n",
      "    23    26    0.00000    5 2087 2114.45130    0.00000   100%  2407  104s\n",
      "    28    24    0.00000    6 2048 2114.45130    0.00000   100%  2302  110s\n",
      "    50    38    0.00000   11 2072 2114.45130    0.00000   100%  1748  119s\n",
      "   174    80    1.94522   40 1622 2114.45130    0.00000   100%   716  122s\n",
      "H  289   129                    1970.5052174    0.00000   100%   433  122s\n",
      "   330   168    1.94522   89 1524 1970.50522    0.00000   100%   393  126s\n",
      "   514   282    3.90989  135 1442 1970.50522    0.00000   100%   279  131s\n",
      "  1022   607  112.84206  253 1330 1970.50522    0.00000   100%   176  135s\n",
      "  1661  1053  256.76870  400 1180 1970.50522    0.00000   100%   111  143s\n",
      "  2019  1299 infeasible  481      1970.50522    0.00000   100%  91.9  150s\n",
      "  2143  1424  336.52261  482 1098 1970.50522    0.00000   100%  87.1  292s\n",
      "H 2146  1425                    1900.4773913    0.00000   100%  87.0  292s\n",
      "  2963  2113  398.76957  569 1032 1900.47739    0.00000   100%  65.6  297s\n",
      "  4075  3045 infeasible  628      1900.47739    0.00000   100%  54.9  301s\n",
      "  5597  4394   42.79478  577  346 1900.47739    0.00000   100%  47.4  306s\n",
      "  5599  4395   42.79478  353 1754 1900.47739    0.00000   100%  47.3  333s\n",
      "  5600  4396   42.79478 1066 1645 1900.47739    0.00000   100%  47.3  368s\n",
      "  5601  4397    0.05836  350 1647 1900.47739    0.00000   100%  47.3  370s\n",
      "  5602  4397   12.70721  253 1055 1900.47739    0.00000   100%  47.3  405s\n",
      "  5603  4398    0.01945   19  949 1900.47739    0.00000   100%  47.3  410s\n",
      "  5604  4399    0.01926  114  645 1900.47739    0.00000   100%  47.3  420s\n",
      "  5606  4400   42.79478  578  634 1900.47739    0.00000   100%  47.3  446s\n",
      "  5607  4401    0.01926   78  646 1900.47739    0.00000   100%  47.3  451s\n",
      "  5608  4401   42.79478  172  592 1900.47739    0.00000   100%  47.3  468s\n",
      "  5609  4402   42.79478 1098  626 1900.47739    0.00000   100%  47.2  474s\n",
      "  5610  4403    9.23158  158  629 1900.47739    0.00000   100%  47.2  504s\n",
      "  5611  4403    0.01926  349  628 1900.47739    0.00000   100%  47.2  506s\n",
      "  5612  4404   13.17419  256  550 1900.47739    0.00000   100%  47.2  556s\n",
      "  5614  4405    0.05836  385  544 1900.47739    0.00000   100%  47.2  564s\n",
      "  5615  4406   42.79478  774  563 1900.47739    0.00000   100%  47.2  566s\n",
      "  5616  4407    0.01926  558  540 1900.47739    0.00000   100%  47.2  581s\n",
      "  5618  4408    0.01926  448  552 1900.47739    0.00000   100%  47.2  589s\n",
      "  5619  4409    8.01198 1257  436 1900.47739    0.00000   100%  47.2  605s\n",
      "  5621  4412    0.00000   13  367 1900.47739    0.00000   100%  70.6  620s\n",
      "  5623  4414    0.00000   14 3779 1900.47739    0.00000   100%  71.4  714s\n",
      "  5626  4416    0.00000   15 2782 1900.47739    0.00000   100%  72.7  744s\n",
      "  5630  4419    0.00000   16 2780 1900.47739    0.00000   100%  74.4  761s\n",
      "  5642  4425    0.00000   17 2553 1900.47739    0.00000   100%  77.4  765s\n",
      "  5664  4433    0.00000   20 2774 1900.47739    0.00000   100%  79.1  786s\n",
      "  5678  4440    0.00000   21 2774 1900.47739    0.00000   100%  83.8  804s\n",
      "  5712  4453    1.94522   23 2660 1900.47739    0.00000   100%  95.0  822s\n",
      "  5850  4508    0.00000   27 1810 1900.47739    0.00000   100%   109  839s\n",
      "  6187  4712    0.03890   95  220 1900.47739    0.00000   100%   133  845s\n",
      "  6565  4895    0.03890  196  206 1900.47739    0.00000   100%   135  852s\n",
      "  6856  4960    0.03890  319  184 1900.47739    0.00000   100%   134  866s\n",
      "  7102  4964  112.06186  472 1373 1900.47739    0.00000   100%   133  875s\n",
      "  7352  5078    0.00000   38  399 1900.47739    0.00000   100%   130  880s\n",
      "  7536  5174    0.00000   65  603 1900.47739    0.00000   100%   129  886s\n",
      "  7781  5205    2.04180  109 1691 1900.47739    0.00000   100%   127  891s\n",
      "  7971  5266    4.09276  147 1374 1900.47739    0.00000   100%   126  902s\n",
      "  7989  5279    4.09276  148 1372 1900.47739    0.00000   100%   126  906s\n",
      "  8162  5371    7.29180  201 1361 1900.47739    0.00000   100%   126  939s\n",
      "H 8243  5181                    1789.6000000    0.00000   100%   126  939s\n",
      "  8370  5210    0.03852   49  380 1789.60000    0.00000   100%   126 1111s\n",
      "  8374  5209    0.19452   50  269 1789.60000    0.00000   100%   126 1118s\n",
      "  8432  5227    0.00000   43  187 1789.60000    0.00000   100%   129 1124s\n",
      "  8525  5256    2.45560   63  966 1789.60000    0.00000   100%   129 1129s\n",
      "  8926  5298    9.60090   54  982 1789.60000    0.00000   100%   127 1143s\n",
      "  9429  5437    0.00000   43  491 1789.60000    0.00000   100%   124 1149s\n",
      "  9949  5463    3.94870   57  951 1789.60000    0.00000   100%   121 1155s\n",
      " 10406  5390    0.01945   61  215 1789.60000    0.00000   100%   117 1163s\n",
      " 11335  5467   90.30309   65 3120 1789.60000    0.00000   100%   112 1170s\n",
      " 12044  5573   19.56542   66 1433 1789.60000    0.00000   100%   108 1341s\n",
      " 12137  5591   19.62320   67 1430 1789.60000    0.00000   100%   108 1345s\n",
      " 12438  5647   50.16292   96 1842 1789.60000    0.00000   100%   107 1356s\n",
      " 12801  5665   28.68887   67 1498 1789.60000    0.00000   100%   106 1362s\n",
      " 13243  5689   14.89420   63 1465 1789.60000    0.00000   100%   105 1368s\n",
      " 13635  5824   50.46626   98 1809 1789.60000    0.00000   100%   105 1375s\n",
      " 13828  5836    0.38596   45 1688 1789.60000    0.00000   100%   106 1383s\n",
      " 14401  6076    0.29976   47 3809 1789.60000    0.00000   100%   104 1390s\n",
      " 14932  6324    0.01926   59  359 1789.60000    0.00000   100%   103 1399s\n",
      " 15151  6418   37.09530   47 2219 1789.60000    0.00000   100%   103 1406s\n",
      " 15532  6522    5.74311   56 1953 1789.60000    0.00000   100%   104 1413s\n",
      " 15873  6639   21.48695   79 2215 1789.60000    0.00000   100%   104 1421s\n",
      " 16383  6704   24.26360   52 1643 1789.60000    0.00000   100%   103 1429s\n",
      " 16873  6876    0.00000   33  282 1789.60000    0.00000   100%   103 1438s\n",
      " 17193  6967   33.30068   53 1797 1789.60000    0.00000   100%   104 1481s\n",
      " 17197  6963   79.26761   54 2823 1789.60000    0.00000   100%   105 1489s\n",
      " 17437  7035   65.53168   93 2617 1789.60000    0.00000   100%   105 1497s\n",
      " 17706  7088   15.94366   62 2419 1789.60000    0.00000   100%   107 1504s\n",
      " 18029  7113    3.24466   48 2402 1789.60000    0.00000   100%   108 1511s\n",
      " 18193  7109 infeasible   77      1789.60000    0.00000   100%   108 1521s\n",
      " 19688  7611 1364.84233  707  846 1789.60000    0.00000   100%   102 1531s\n",
      " 20880  8067  848.77307  370 1488 1789.60000    0.00000   100%  98.4 2049s\n",
      " 22121  8413    1.96448   49  878 1789.60000    0.00000   100%  94.9 2265s\n",
      " 22134  8414    1.96448   50  872 1789.60000    0.00000   100%  94.8 2271s\n",
      " 22368  8495  288.84533   41 2182 1789.60000    0.00000   100%  94.7 2281s\n",
      " 23893  9095    0.00000   36  476 1789.60000    0.00000   100%  90.0 2289s\n",
      " 24935  9524    0.00000   58  989 1789.60000    0.00000   100%  87.6 2307s\n",
      " 25137  9559    0.03871   59 1139 1789.60000    0.00000   100%  87.6 2312s\n",
      " 25333  9688    2.11932   94 1022 1789.60000    0.00000   100%  88.3 2316s\n",
      " 25496  9774    2.13839   66 1358 1789.60000    0.00000   100%  89.1 2323s\n",
      " 25704  9912    0.10689   76 1197 1789.60000    0.00000   100%  89.9 2328s\n",
      " 25905 10020   16.92146  143 2704 1789.60000    0.00000   100%  90.7 2335s\n",
      " 26231 10224    2.08061   90  623 1789.60000    0.00000   100%  91.5 2502s\n",
      " 26252 10235   14.39764  102 3001 1789.60000    0.00000   100%  91.7 2507s\n",
      " 26385 10304 infeasible  115      1789.60000    0.00000   100%  92.0 2513s\n",
      " 26650 10446    0.05797   56 1233 1789.60000    0.00000   100%  92.1 2519s\n",
      " 26971 10690  134.96323  133 2589 1789.60000    0.00000   100%  92.4 2526s\n",
      " 27241 10877    0.00000   53  485 1789.60000    0.00000   100%  93.3 2532s\n",
      " 27538 11049    0.00000   43  616 1789.60000    0.00000   100%  94.1 2541s\n",
      " 27734 11177    9.78444   58 2763 1789.60000    0.00000   100%  95.6 2551s\n",
      " 27781 11197   11.67130   64 2305 1789.60000    0.00000   100%  96.6 2557s\n",
      " 27931 11285   11.67130   73 2287 1789.60000    0.00000   100%  96.9 2562s\n",
      " 28039 11324   13.86384   81 3159 1789.60000    0.00000   100%  97.3 2567s\n",
      " 28226 11404   13.94366   97 3424 1789.60000    0.00000   100%  97.7 2574s\n",
      " 28739 11729   22.50131  130 3462 1789.60000    0.00000   100%  97.2 2582s\n",
      " 29010 11820   43.55342   75 2316 1789.60000    0.00000   100%  97.6 2590s\n",
      " 30106 11851  212.63910  221 2301 1789.60000    0.00000   100%  95.2 2597s\n",
      " 30899 12163    0.00000   44  278 1789.60000    0.00000   100%  94.2 2606s\n",
      " 31818 12489  487.12523   73 2677 1789.60000    0.00000   100%  93.6 2614s\n",
      " 32884 12752  565.44513  176 2527 1789.60000    0.00000   100%  91.6 2622s\n",
      " 34142 12999 1076.32345  268 2428 1789.60000    0.00000   100%  89.2 2630s\n",
      " 35831 13209   91.40577   57 2858 1789.60000    0.00000   100%  85.7 2638s\n",
      " 36698 13472 infeasible   61      1789.60000    0.00000   100%  84.3 2645s\n",
      " 37189 13745    0.00000   43  157 1789.60000    0.00000   100%  84.0 2652s\n",
      " 38073 13835    0.00000   53  471 1789.60000    0.00000   100%  82.6 2692s\n",
      " 38114 13857 infeasible   44      1789.60000    0.00000   100%  82.6 2745s\n",
      " 38300 13914   73.55291  140 2322 1789.60000    0.00000   100%  82.9 2754s\n",
      " 39159 14192  438.21014  704 2101 1789.60000    0.00000   100%  81.7 2761s\n",
      " 40055 14382 1174.08031 1318 1579 1789.60000    0.00000   100%  80.3 2766s\n",
      " 40819 14562   34.54417   65 1816 1789.60000    0.00000   100%  79.4 2770s\n",
      " 41209 14809   90.93872   65 3127 1789.60000    0.00000   100%  79.3 2776s\n",
      " 41715 15073  593.36468   96 2472 1789.60000    0.00000   100%  79.3 2782s\n",
      " 42138 15238   12.23792   51 1690 1789.60000    0.00000   100%  79.2 2787s\n",
      " 42555 15298 infeasible   71      1789.60000    0.00000   100%  78.8 2794s\n",
      " 43620 15608 infeasible   57      1789.60000    0.00000   100%  77.3 2801s\n",
      " 44346 15804 infeasible   72      1789.60000    0.00000   100%  76.4 2806s\n",
      " 44778 15966 infeasible   66      1789.60000    0.00000   100%  76.1 2811s\n",
      " 44969 16046   12.17114   60 1688 1789.60000    0.00000   100%  76.3 2819s\n",
      " 45011 16044   12.23368   61 1692 1789.60000    0.00000   100%  76.7 2823s\n",
      " 45077 16060   17.15142   72 1370 1789.60000    0.00000   100%  76.9 2831s\n",
      " 45150 16083   32.51710   85 1446 1789.60000    0.00000   100%  77.0 2837s\n",
      " 45506 16317 infeasible   43      1789.60000    0.00000   100%  77.1 2841s\n",
      " 45966 16646    0.00000   31  354 1789.60000    0.00000   100%  77.2 2848s\n",
      " 46226 16801   34.33366   56 1542 1789.60000    0.00000   100%  77.4 2852s\n",
      " 46354 16874    3.89043   30 1951 1789.60000    0.00000   100%  77.7 2858s\n",
      " 47139 16930    3.99733   34 2156 1789.60000    0.00000   100%  77.0 2863s\n",
      " 47390 16971   12.06016   50 2083 1789.60000    0.00000   100%  77.0 2868s\n",
      " 47649 17072  765.48851   30 3701 1789.60000    0.00000   100%  77.1 2874s\n",
      " 48132 17361 infeasible   63      1789.60000    0.00000   100%  77.0 2880s\n",
      " 48870 17785    6.01034   67 2185 1789.60000    0.00000   100%  76.6 2889s\n",
      " 49033 17877 infeasible   77      1789.60000    0.00000   100%  76.9 2893s\n",
      " 49156 17945   15.99175   92 2437 1789.60000    0.00000   100%  77.1 2898s\n",
      " 49408 18095    6.30193   62 2110 1789.60000    0.00000   100%  77.3 2903s\n",
      " 49812 18232   43.53088   81 2766 1789.60000    0.00000   100%  77.3 2909s\n",
      " 50015 18323    2.00300   60  214 1789.60000    0.00000   100%  77.5 2914s\n",
      " 50295 18442   44.87520   74 2584 1789.60000    0.00000   100%  77.8 2918s\n",
      " 50377 18461 infeasible   87      1789.60000    0.00000   100%  78.0 2922s\n",
      " 50504 18501 infeasible  100      1789.60000    0.00000   100%  78.2 2927s\n",
      " 50774 18582  178.77761  141 2448 1789.60000    0.00000   100%  78.9 2932s\n",
      " 51023 18694   11.21543   62 2283 1789.60000    0.00000   100%  79.3 2956s\n",
      " 51115 18747 infeasible   83      1789.60000    0.00000   100%  79.6 2964s\n",
      " 51361 18886  100.66019   67 2021 1789.60000    0.00000   100%  79.8 2968s\n",
      " 51636 19033 infeasible   49      1789.60000    0.00000   100%  80.3 2974s\n",
      " 51901 19193    3.89043   50 2631 1789.60000    0.00000   100%  80.6 2981s\n",
      " 52277 19388    7.78087   57 2163 1789.60000    0.00000   100%  80.5 2989s\n",
      " 52962 19724 infeasible   63      1789.60000    0.00000   100%  79.9 2999s\n",
      " 53410 19996   19.39979   75 2390 1789.60000    0.00000   100%  79.7 3005s\n",
      " 54076 20322  420.08915   51 2274 1789.60000    0.00000   100%  79.6 3071s\n",
      " 54852 20614    5.83565   45 2141 1789.60000    0.00000   100%  78.7 3077s\n",
      " 54980 20679 infeasible   49      1789.60000    0.00000   100%  79.1 3083s\n",
      " 55221 20842   42.68346   68 2313 1789.60000    0.00000   100%  79.2 3090s\n",
      " 55984 21244    0.00109   39  457 1789.60000    0.00000   100%  79.2 3098s\n",
      " 56741 21666  280.85954  553 1805 1789.60000    0.00000   100%  78.9 3127s\n",
      " 56745 21664 1373.83829  554  681 1789.60000    0.00000   100%  79.0 3133s\n",
      " 57175 21804    0.00000   41  214 1789.60000    0.00000   100%  78.7 3139s\n",
      " 57926 22071 infeasible  177      1789.60000    0.00000   100%  79.1 3148s\n",
      " 58667 22179  387.74789  531 1721 1789.60000    0.00000   100%  79.1 3157s\n",
      " 59277 22296  679.19865  821 1386 1789.60000    0.00000   100%  79.0 3166s\n",
      " 59899 22384   10.46296   58 2155 1789.60000    0.00000   100%  79.0 3171s\n",
      " 60183 22493   86.60962  108 2369 1789.60000    0.00000   100%  79.2 3179s\n",
      " 60555 22660 infeasible   47      1789.60000    0.00000   100%  79.4 3187s\n",
      " 60986 22857    0.00000   45  330 1789.60000    0.00000   100%  79.6 3193s\n",
      " 61793 23208     cutoff   62      1789.60000    0.00000   100%  79.3 3200s\n",
      " 62811 23781   20.36643   67 2134 1789.60000    0.00000   100%  78.7 3206s\n",
      " 63824 24358 infeasible   46      1789.60000    0.00000   100%  78.1 3533s\n",
      " 64026 24488    0.00000   47  896 1789.60000    0.00000   100%  78.0 3538s\n",
      " 64159 24541    2.36893   53 1290 1789.60000    0.00000   100%  78.2 3543s\n",
      " 64300 24576    0.00000   58 1218 1789.60000    0.00000   100%  78.3 3548s\n",
      " 64475 24616    0.11575   72 1275 1789.60000    0.00000   100%  78.2 3554s\n",
      " 64961 24810    5.91346   47 2070 1789.60000    0.00000   100%  78.3 3561s\n",
      " 65356 24957    7.39934   61 1934 1789.60000    0.00000   100%  78.6 3567s\n",
      " 65722 25176   24.72400   74 2428 1789.60000    0.00000   100%  78.8 3572s\n",
      " 65963 25312    0.05778   61 2013 1789.60000    0.00000   100%  79.0 3580s\n",
      " 66627 25558    0.01945   47  544 1789.60000    0.00000   100%  78.9 3585s\n",
      " 67153 25765 infeasible   65      1789.60000    0.00000   100%  79.1 3594s\n",
      " 68179 26354 infeasible   89      1789.60000    0.00000   100%  78.4 3598s\n",
      " 68468 26461 infeasible   92      1789.60000    0.00000   100%  78.5 3604s\n",
      " 69250 26843 infeasible  331      1789.60000    0.00000   100%  78.4 3609s\n",
      " 69616 26939    4.84969   50 2165 1789.60000    0.00000   100%  78.7 3617s\n",
      " 69664 26962   42.43521   55 2121 1789.60000    0.00000   100%  78.8 3621s\n",
      " 69769 27005 infeasible   64      1789.60000    0.00000   100%  79.1 3628s\n",
      " 70397 27372  483.53174  386 2083 1789.60000    0.00000   100%  78.9 3633s\n",
      " 71132 27770    0.11556   48  280 1789.60000    0.00000   100%  78.8 3638s\n",
      " 71646 27988   52.78415   55 1926 1789.60000    0.00000   100%  78.8 3645s\n",
      " 72591 28402 infeasible   53      1789.60000    0.00000   100%  78.5 3650s\n",
      " 73215 28726   31.78938   49 2713 1789.60000    0.00000   100%  78.7 3660s\n",
      " 74233 29236  247.57706   79 2604 1789.60000    0.00000   100%  78.8 3669s\n",
      " 74804 29566 infeasible   55      1789.60000    0.00000   100%  78.7 3675s\n",
      " 75220 29727 infeasible   78      1789.60000    0.00000   100%  78.9 3684s\n",
      " 75743 29852 infeasible  151      1789.60000    0.00000   100%  79.3 3690s\n",
      " 76312 29926    0.36593   32 2158 1789.60000    0.00000   100%  79.4 3695s\n",
      " 76529 30016    1.40489   35 4312 1789.60000    0.00000   100%  79.7 3701s\n",
      " 77171 30288   14.98395   41 2768 1789.60000    0.00000   100%  79.7 3705s\n",
      " 77459 30458   33.75376   51 1517 1789.60000    0.00000   100%  79.8 3711s\n",
      " 77798 30632 infeasible   54      1789.60000    0.00000   100%  79.8 3717s\n",
      " 78090 30743  188.06092  104 1844 1789.60000    0.00000   100%  80.1 3727s\n",
      " 78544 30993    0.03852   49  750 1789.60000    0.00000   100%  80.4 3730s\n",
      " 78639 31021    0.41498   52 1101 1789.60000    0.00000   100%  80.7 3737s\n",
      " 78849 31124 infeasible   52      1789.60000    0.00000   100%  80.8 3741s\n",
      " 78974 31173 infeasible   59      1789.60000    0.00000   100%  81.1 3747s\n",
      " 79292 31231  371.40036   65 1847 1789.60000    0.00000   100%  81.3 3753s\n",
      " 79568 31395 infeasible   49      1789.60000    0.00000   100%  81.4 3758s\n",
      " 79795 31462    2.78922   75 1024 1789.60000    0.00000   100%  81.5 3765s\n",
      " 80472 31837   36.41170   69 2223 1789.60000    0.00000   100%  81.6 3772s\n",
      " 81148 32239    0.07704   79  407 1789.60000    0.00000   100%  81.5 3780s\n",
      " 81609 32515    0.00000   43  653 1789.60000    0.00000   100%  81.6 3785s\n",
      " 81945 32744 infeasible   56      1789.60000    0.00000   100%  81.8 3791s\n",
      " 82253 32945 infeasible   69      1789.60000    0.00000   100%  81.9 3800s\n",
      " 82606 33040    0.00000   43  668 1789.60000    0.00000   100%  82.0 3811s\n",
      " 83325 33329    0.00000   31 1226 1789.60000    0.00000   100%  82.0 3817s\n",
      " 83394 33359 infeasible   56      1789.60000    0.00000   100%  82.3 3827s\n",
      " 83628 33397 infeasible   79      1789.60000    0.00000   100%  82.2 3836s\n",
      " 84082 33590    0.09726   68  713 1789.60000    0.00000   100%  82.3 3849s\n",
      " 84280 33702    0.13617   65 1262 1789.60000    0.00000   100%  82.5 3859s\n",
      " 84611 33856   68.54388   77 2106 1789.60000    0.00000   100%  82.6 3873s\n",
      " 85469 34244  700.78402  711 1430 1789.60000    0.00000   100%  82.4 3894s\n",
      " 86482 34453 1491.10250 1528  646 1789.60000    0.00000   100%  82.0 3906s\n",
      " 86624 34526    0.00000   66 1844 1789.60000    0.00000   100%  82.3 3922s\n",
      " 86845 34634    0.00000   73 1122 1789.60000    0.00000   100%  82.7 3929s\n",
      " 87082 34754    0.00000   83 1445 1789.60000    0.00000   100%  83.1 3935s\n",
      " 87188 34781    1.94522  103 1396 1789.60000    0.00000   100%  83.3 3945s\n",
      " 87373 34876    0.00000   97 1321 1789.60000    0.00000   100%  83.7 3958s\n",
      " 87492 34932    1.94522   33 2133 1789.60000    0.00000   100%  84.2 3969s\n",
      " 87538 34960    0.00000   24  326 1789.60000    0.00000   100%  84.5 3979s\n",
      " 87925 35186    0.00000   58  226 1789.60000    0.00000   100%  84.9 3987s\n",
      " 89033 35548  358.65726  615 2176 1789.60000    0.00000   100%  84.2 3994s\n",
      " 90125 35977  230.62921  437 2339 1789.60000    0.00000   100%  83.9 4001s\n",
      " 91213 36285  361.78978  579 2161 1789.60000    0.00000   100%  83.6 4007s\n",
      " 91976 36446 infeasible  103      1789.60000    0.00000   100%  83.3 4017s\n",
      " 93782 36670  124.36141  217 2415 1789.60000    0.00000   100%  83.1 4023s\n",
      " 94791 36892   68.76806  182 2344 1789.60000    0.00000   100%  83.1 4032s\n",
      " 94957 36966    0.00000   43 2481 1789.60000    0.00000   100%  83.2 4038s\n",
      " 95543 37238    0.23323   57 1491 1789.60000    0.00000   100%  82.9 4044s\n",
      " 96149 37432    0.13539   52 2512 1789.60000    0.00000   100%  82.8 4048s\n",
      " 96242 37446    1.01719   82 1918 1789.60000    0.00000   100%  83.1 4055s\n",
      " 96724 37502    0.00000   73 1668 1789.60000    0.00000   100%  83.2 4060s\n",
      " 97042 37561    8.25061   77 2676 1789.60000    0.00000   100%  83.4 4068s\n",
      " 98284 37934  330.79462  690 2185 1789.60000    0.00000   100%  83.7 4073s\n",
      " 98534 38006    0.00423   53 1900 1789.60000    0.00000   100%  84.0 4078s\n",
      " 98669 38050    0.00000   44  303 1789.60000    0.00000   100%  84.2 4084s\n",
      " 98839 38079    0.00000  103 1509 1789.60000    0.00000   100%  84.5 4090s\n",
      " 99206 38202    0.73629   79 1766 1789.60000    0.00000   100%  84.9 4101s\n",
      " 99393 38276    0.00000   53 1784 1789.60000    0.00000   100%  85.0 4108s\n",
      " 99943 38466    3.01162   66 1839 1789.60000    0.00000   100%  84.8 4112s\n",
      " 100067 38498    0.11633   57 1889 1789.60000    0.00000   100%  84.9 4119s\n",
      " 100833 38825    0.00000   43 2141 1789.60000    0.00000   100%  84.7 4123s\n",
      " 100999 38893    2.62200   44 1824 1789.60000    0.00000   100%  84.8 4129s\n",
      " 101193 38982    0.00000  105  330 1789.60000    0.00000   100%  84.9 4137s\n",
      " 101552 39091    0.00000   63  235 1789.60000    0.00000   100%  84.9 4144s\n",
      " 102419 39390   14.68177   95 2596 1789.60000    0.00000   100%  84.5 4150s\n",
      " 103635 39573 infeasible   63      1789.60000    0.00000   100%  84.3 4163s\n",
      " 104039 39735 infeasible   83      1789.60000    0.00000   100%  84.4 4511s\n",
      "H104040 39425                    1760.4217391    0.00000   100%  84.4 4511s\n",
      " 104094 39412    0.00000   93 2333 1760.42174    0.00000   100%  84.6 4535s\n",
      " 104199 39478    1.94522  115 2298 1760.42174    0.00000   100%  84.7 4542s\n",
      " 104271 39509    3.15125  137 2159 1760.42174    0.00000   100%  84.9 4547s\n",
      " 104329 39541    0.00000   40  335 1760.42174    0.00000   100%  84.9 4576s\n",
      " 104413 39601    0.05778   45 1735 1760.42174    0.00000   100%  85.2 4581s\n",
      " 104495 39630    0.94584   84 1699 1760.42174    0.00000   100%  85.2 4595s\n",
      " 104771 39787    0.00000   43  916 1760.42174    0.00000   100%  85.4 4610s\n",
      " 104847 39840    2.34967   40  297 1760.42174    0.00000   100%  85.7 4620s\n",
      " 105086 39874  379.55082  216 1234 1760.42174    0.00000   100%  85.8 4634s\n",
      " 105935 39899 1418.30345  738  944 1760.42174    0.00000   100%  85.5 4644s\n",
      " 106726 39943  791.19580  420 1270 1760.42174    0.00000   100%  85.2 4658s\n",
      " 107295 39985    0.00000   53 1328 1760.42174    0.00000   100%  85.2 4666s\n",
      " 107358 40038    0.00000   63 1656 1760.42174    0.00000   100%  85.6 4682s\n",
      " 107547 40158    0.00000   73 1543 1760.42174    0.00000   100%  85.9 4689s\n",
      " 107597 40183    0.00000   82 2097 1760.42174    0.00000   100%  86.2 4697s\n",
      " 107713 40256    0.00000   89 1892 1760.42174    0.00000   100%  86.5 4705s\n",
      " 107802 40309    0.00000   93 2185 1760.42174    0.00000   100%  86.9 4715s\n",
      " 107841 40334    0.00000  103 2250 1760.42174    0.00000   100%  87.3 4731s\n",
      " 107935 40380    0.03890  114 3546 1760.42174    0.00000   100%  87.7 4740s\n",
      " 108133 40544    2.10083  229 3299 1760.42174    0.00000   100%  87.9 4751s\n",
      " 108197 40570    0.00000   43 1471 1760.42174    0.00000   100%  88.3 4759s\n",
      " 108251 40578    0.00000   53  950 1760.42174    0.00000   100%  88.7 4768s\n",
      " 108317 40595    0.00000   63 1442 1760.42174    0.00000   100%  89.0 4778s\n",
      " 108408 40617 infeasible   63      1760.42174    0.00000   100%  89.4 4788s\n",
      " 108470 40588    0.00000   43 1291 1760.42174    0.00000   100%  89.8 4799s\n",
      " 108576 40590    0.00000   53 1174 1760.42174    0.00000   100%  90.2 4806s\n",
      " 108675 40610    0.00000   53 1048 1760.42174    0.00000   100%  90.5 4815s\n",
      " 108753 40593 infeasible   63      1760.42174    0.00000   100%  90.6 4823s\n",
      " 108872 40594 infeasible   54      1760.42174    0.00000   100%  90.9 4830s\n",
      " 108937 40567 infeasible   60      1760.42174    0.00000   100%  91.0 4839s\n",
      " 109178 40640    0.00000  113 2246 1760.42174    0.00000   100%  91.4 4846s\n",
      " 109441 40669    0.00000  123 2039 1760.42174    0.00000   100%  91.6 4850s\n",
      " 109824 40732    2.19810   70 1495 1760.42174    0.00000   100%  91.6 4855s\n",
      " 110097 40692 infeasible  172      1760.42174    0.00000   100%  91.7 4865s\n",
      " 110455 40816    0.00000   42  829 1760.42174    0.00000   100%  91.9 4876s\n",
      " 111116 41068 infeasible   43      1760.42174    0.00000   100%  91.8 4886s\n",
      " 111631 41282 infeasible   44      1760.42174    0.00000   100%  91.7 4896s\n",
      " 112158 41521    0.00000   63  774 1760.42174    0.00000   100%  91.9 4906s\n",
      " 112522 41711    0.00000   43 1183 1760.42174    0.00000   100%  92.2 4916s\n",
      " 112968 41844    0.00000   53  785 1760.42174    0.00000   100%  92.2 4925s\n",
      " 113744 42121    0.00000   43 1325 1760.42174    0.00000   100%  92.3 4939s\n",
      " 114037 42253 infeasible   63      1760.42174    0.00000   100%  92.7 4950s\n",
      " 114082 42240    0.00000   43 2589 1760.42174    0.00000   100%  93.1 4968s\n",
      " 114181 42279    0.00000   43  606 1760.42174    0.00000   100%  93.7 4982s\n",
      " 114234 42259    0.00000   53 2504 1760.42174    0.00000   100%  94.2 4996s\n",
      " 114337 42221    0.00000   43 3271 1760.42174    0.00000   100%  94.6 5004s\n",
      " 114454 42219 infeasible  131      1760.42174    0.00000   100%  94.9 5023s\n",
      " 114557 42195    0.00000   53  956 1760.42174    0.00000   100%  95.5 5033s\n",
      " 114660 42239    0.00000   39 3554 1760.42174    0.00000   100%  95.8 5045s\n",
      " 114703 42204 infeasible   43      1760.42174    0.00000   100%  96.2 5055s\n",
      " 114847 42211 infeasible   74      1760.42174    0.00000   100%  96.6 5066s\n",
      " 114976 42193    0.00000   53 1504 1760.42174    0.00000   100%  97.2 5079s\n",
      " 115148 42186 infeasible   51      1760.42174    0.00000   100%  97.6 5088s\n",
      " 115229 42145    0.00000   53  822 1760.42174    0.00000   100%  97.9 5097s\n",
      " 115506 42193    0.00000   53  903 1760.42174    0.00000   100%  98.2 5104s\n",
      " 115653 42198    0.00000   63 2217 1760.42174    0.00000   100%  98.4 5112s\n",
      " 115734 42169 infeasible  134      1760.42174    0.00000   100%  98.4 5121s\n",
      " 115859 42162 infeasible   43      1760.42174    0.00000   100%  98.7 5130s\n",
      " 116066 42162 infeasible   54      1760.42174    0.00000   100%  99.1 5137s\n",
      " 116170 42100 infeasible   64      1760.42174    0.00000   100%  99.3 5145s\n",
      " 116978 42613    1.94522   60 1018 1760.42174    0.00000   100%  98.9 5155s\n",
      " 117955 43007    0.00000   63 1534 1760.42174    0.00000   100%  98.7 5165s\n",
      " 119370 43880 infeasible   39      1760.42174    0.00000   100%  98.2 5174s\n",
      " 121371 44910    1.18658   64 2897 1760.42174    0.00000   100%  97.2 5181s\n",
      " 122755 45591 infeasible   56      1760.42174    0.00000   100%  96.6 5187s\n",
      " 123988 46094 infeasible   84      1760.42174    0.00000   100%  96.1 5190s\n",
      " 124906 46301    0.00000   78  725 1760.42174    0.00000   100%  95.6 5195s\n",
      " 125787 46553 infeasible   90      1760.42174    0.00000   100%  95.1 5200s\n",
      " 125852 46547 infeasible   42      1760.42174    0.00000   100%  95.2 5206s\n",
      " 125867 46530    0.00000   41 1679 1760.42174    0.00000   100%  95.4 5213s\n",
      " 125924 46527    0.00000   43 1602 1760.42174    0.00000   100%  95.6 5217s\n",
      " 125985 46482    0.00000   44 1954 1760.42174    0.00000   100%  95.8 5221s\n",
      " 126069 46469 infeasible   42      1760.42174    0.00000   100%  95.9 5225s\n",
      " 126240 46505    0.00000   43  835 1760.42174    0.00000   100%  96.1 5232s\n",
      " 126414 46583    0.00000  103 1187 1760.42174    0.00000   100%  96.3 5663s\n",
      " 126552 46627    0.00000  104 1187 1760.42174    0.00000   100%  96.3 5675s\n",
      " 126742 46565    0.00000   73  706 1760.42174    0.00000   100%  96.4 5693s\n",
      " 126831 46581    0.00000   83 1119 1760.42174    0.00000   100%  96.6 5697s\n",
      " 126896 46561    0.00000  103 1111 1760.42174    0.00000   100%  96.8 5705s\n",
      " 126981 46565 infeasible   40      1760.42174    0.00000   100%  96.9 5716s\n",
      " 127140 46627    0.09630   43 3335 1760.42174    0.00000   100%  97.0 5727s\n",
      " 127303 46655    1.25187   54 3171 1760.42174    0.00000   100%  97.1 5739s\n",
      " 127435 46652    3.19709   69 3400 1760.42174    0.00000   100%  97.2 5747s\n",
      " 127897 46816 infeasible   92      1760.42174    0.00000   100%  97.0 5757s\n",
      " 128059 46883 infeasible   84      1760.42174    0.00000   100%  97.1 5784s\n",
      " 128304 47042    0.00000   33 2611 1760.42174    0.00000   100%  97.5 5793s\n",
      " 128373 47047    0.00000   43 2760 1760.42174    0.00000   100%  97.7 5807s\n",
      " 129162 47531 infeasible   33      1760.42174    0.00000   100%  97.7 5814s\n",
      " 130011 48014    0.00000   32 2808 1760.42174    0.00000   100%  97.5 5820s\n",
      " 131022 48695    0.64500  149 2882 1760.42174    0.00000   100%  97.0 5826s\n",
      " 132378 49564 infeasible   40      1760.42174    0.00000   100%  96.4 5841s\n",
      " 133029 49940 infeasible   85      1760.42174    0.00000   100%  96.2 5861s\n",
      " 133263 50061 infeasible  100      1760.42174    0.00000   100%  96.5 5877s\n",
      " 133439 50131 infeasible   30      1760.42174    0.00000   100%  96.6 5889s\n",
      " 133631 50250    0.01945   33 2176 1760.42174    0.00000   100%  96.8 5913s\n",
      " 134252 50599    0.03890   52 1505 1760.42174    0.00000   100%  97.1 5932s\n",
      " 134466 50710   56.99487  121  981 1760.42174    0.00000   100%  97.3 5951s\n",
      " 135373 51042    0.01945   33 1699 1760.42174    0.00000   100%  97.2 5970s\n",
      " 135603 51108 infeasible   49      1760.42174    0.00000   100%  97.4 5987s\n",
      " 136191 51512    0.00000   33 1323 1760.42174    0.00000   100%  97.5 5997s\n",
      " 136259 51524    0.00000   52 1590 1760.42174    0.00000   100%  97.9 6006s\n",
      " 136755 51857    0.00000   63 2246 1760.42174    0.00000   100%  98.0 6017s\n",
      " 136968 51960    0.00000  103 1720 1760.42174    0.00000   100%  98.3 6025s\n",
      " 137319 52116 infeasible  133      1760.42174    0.00000   100%  98.5 6034s\n",
      " 137450 52145 infeasible   46      1760.42174    0.00000   100%  98.7 6042s\n",
      " 137775 52275 infeasible   43      1760.42174    0.00000   100%  99.0 6052s\n",
      " 137859 52243    0.00000   53 1123 1760.42174    0.00000   100%  99.1 6059s\n",
      " 137933 52234 infeasible   48      1760.42174    0.00000   100%  99.2 6071s\n",
      " 138027 52268    0.00000   73  812 1760.42174    0.00000   100%  99.5 6082s\n",
      " 138351 52424    0.00000   93 1704 1760.42174    0.00000   100%   100 6087s\n",
      " 138617 52511 infeasible  152      1760.42174    0.00000   100%   100 6093s\n",
      " 138724 52479 infeasible   54      1760.42174    0.00000   100%   100 6101s\n",
      " 139019 52583 infeasible   38      1760.42174    0.00000   100%   100 6108s\n",
      " 139361 52590 infeasible   46      1760.42174    0.00000   100%   100 6117s\n",
      " 140100 52987 infeasible   73      1760.42174    0.00000   100%   100 6132s\n",
      " 140265 53026    0.00000   53 1163 1760.42174    0.00000   100%   101 6146s\n",
      " 140374 53036    0.00000   33 1733 1760.42174    0.00000   100%   101 6155s\n",
      " 140716 53014 infeasible   63      1760.42174    0.00000   100%   102 6166s\n",
      " 140794 53003    0.01926   37  499 1760.42174    0.00000   100%   102 6176s\n",
      " 140942 53024 infeasible   51      1760.42174    0.00000   100%   102 6183s\n",
      " 141204 53099    0.00000   73 1445 1760.42174    0.00000   100%   103 6193s\n",
      " 141750 53319 infeasible   63      1760.42174    0.00000   100%   103 6202s\n",
      " 142161 53376    0.00000   83 1688 1760.42174    0.00000   100%   104 6207s\n",
      " 142522 53346 infeasible   68      1760.42174    0.00000   100%   104 6214s\n",
      " 142629 53287 infeasible   65      1760.42174    0.00000   100%   104 6218s\n",
      " 142870 53321 infeasible   97      1760.42174    0.00000   100%   104 6224s\n",
      " 143062 53325 infeasible   46      1760.42174    0.00000   100%   104 6229s\n",
      " 143665 53431 infeasible   44      1760.42174    0.00000   100%   104 6235s\n",
      " 145349 53990   23.63439   90 1293 1760.42174    0.00000   100%   103 6245s\n",
      " 147196 54655  147.79762  126 2307 1760.42174    0.00000   100%   102 6250s\n",
      " 148247 55062 infeasible  110      1760.42174    0.00000   100%   102 6256s\n",
      " 149372 55408   10.23184   73 1101 1760.42174    0.00000   100%   101 6262s\n",
      " 150177 55773    0.00000   33  776 1760.42174    0.00000   100%   101 6266s\n",
      " 150289 55790 infeasible   43      1760.42174    0.00000   100%   101 6271s\n",
      " 150409 55798    5.25209   74 1627 1760.42174    0.00000   100%   101 6276s\n",
      " 151283 56058 infeasible   54      1760.42174    0.00000   100%   101 6284s\n",
      " 151428 56035  417.61639   95 1189 1760.42174    0.00000   100%   101 6288s\n",
      " 151968 56100    0.00000   53  665 1760.42174    0.00000   100%   101 6297s\n",
      " 152620 56299    0.00000   88 2177 1760.42174    0.00000   100%   101 6302s\n",
      " 152780 56297    0.00000   93 1188 1760.42174    0.00000   100%   101 6308s\n",
      " 153011 56424   40.38271   49 1405 1760.42174    0.00000   100%   102 6314s\n",
      " 153348 56521  280.11130  293 1154 1760.42174    0.00000   100%   102 6322s\n",
      " 153627 56615  378.44531  427 1582 1760.42174    0.00000   100%   102 6328s\n",
      " 153998 56745  856.13512  651 1630 1760.42174    0.00000   100%   102 6333s\n",
      " 154576 56925 infeasible   45      1760.42174    0.00000   100%   102 6338s\n",
      " 154880 56929 infeasible   43      1760.42174    0.00000   100%   102 6343s\n",
      " 155542 57082  242.92241  319 1797 1760.42174    0.00000   100%   102 6348s\n",
      " 156218 57418    0.00000   33  128 1760.42174    0.00000   100%   101 6355s\n",
      " 156393 57423 infeasible   44      1760.42174    0.00000   100%   102 6364s\n",
      " 156459 57409    0.00000   45  291 1760.42174    0.00000   100%   102 6368s\n",
      " 156762 57480  369.52621  277 1943 1760.42174    0.00000   100%   102 6376s\n",
      " 157377 57724    0.00000   43 2487 1760.42174    0.00000   100%   102 6380s\n",
      " 157558 57773    0.00000   53 1681 1760.42174    0.00000   100%   102 6387s\n",
      " 157628 57774 infeasible   63      1760.42174    0.00000   100%   102 6391s\n",
      " 157709 57774    0.00000   61 1284 1760.42174    0.00000   100%   102 6395s\n",
      " 157795 57777 infeasible   72      1760.42174    0.00000   100%   102 6400s\n",
      " 157838 57743    0.00000   33 1896 1760.42174    0.00000   100%   102 6409s\n",
      " 157993 57776    0.00000   43  965 1760.42174    0.00000   100%   103 6417s\n",
      " 158200 57843 infeasible   64      1760.42174    0.00000   100%   103 6422s\n",
      " 158298 57887    0.00000   43 2303 1760.42174    0.00000   100%   103 6431s\n",
      " 158509 58022    0.00000   58 2289 1760.42174    0.00000   100%   103 6438s\n",
      " 158629 58033    0.00000   68 2212 1760.42174    0.00000   100%   103 6457s\n",
      " 158860 58127    0.00000   33 2812 1760.42174    0.00000   100%   103 6464s\n",
      " 159333 58322    0.00000   43 2525 1760.42174    0.00000   100%   103 6471s\n",
      " 160245 58639    0.01945   65 2441 1760.42174    0.00000   100%   103 6478s\n",
      " 161214 59184 infeasible   53      1760.42174    0.00000   100%   103 6485s\n",
      " 162126 59515   14.23899  155 3138 1760.42174    0.00000   100%   103 6490s\n",
      " 162623 59831 infeasible  159      1760.42174    0.00000   100%   102 6495s\n",
      " 163165 60048    9.48111  179 3221 1760.42174    0.00000   100%   102 6508s\n",
      " 163576 60198    1.94522   43 3165 1760.42174    0.00000   100%   102 6514s\n",
      " 164660 60821    2.00357  129 2629 1760.42174    0.00000   100%   102 6518s\n",
      " 165124 61088 infeasible  149      1760.42174    0.00000   100%   102 6524s\n",
      " 165390 61150    0.00000   33 1787 1760.42174    0.00000   100%   102 6536s\n",
      " 165738 61357    0.00000   43 2291 1760.42174    0.00000   100%   102 6561s\n",
      " 165857 61416    2.12029   92 3335 1760.42174    0.00000   100%   103 6572s\n",
      " 165918 61440    7.91703  105 3471 1760.42174    0.00000   100%   103 6595s\n",
      " 166213 61581    0.00117   49 2449 1760.42174    0.00000   100%   103 6606s\n",
      " 166258 61605    0.09697   59 1821 1760.42174    0.00000   100%   103 6842s\n",
      " 166369 61676    0.26155   60 2245 1760.42174    0.00000   100%   103 6849s\n",
      " 166434 61708    0.00000   35 1847 1760.42174    0.00000   100%   103 6866s\n",
      " 166479 61729    0.00000   43 1482 1760.42174    0.00000   100%   104 6884s\n",
      " 166528 61752 infeasible   48      1760.42174    0.00000   100%   104 6909s\n",
      " 166581 61778    0.00000   53 1651 1760.42174    0.00000   100%   104 6935s\n",
      " 166665 61785    0.21186   78 2392 1760.42174    0.00000   100%   104 6959s\n",
      " 166743 61819 infeasible   33      1760.42174    0.00000   100%   105 6980s\n",
      " 166781 61828    0.00000   43 3391 1760.42174    0.00000   100%   105 6991s\n",
      " 166869 61863    0.00000   54  864 1760.42174    0.00000   100%   105 6998s\n",
      " 167290 62177    0.00000   73 1583 1760.42174    0.00000   100%   105 7011s\n",
      " 167871 62476 infeasible   43      1760.42174    0.00000   100%   105 7018s\n",
      " 168289 62649    0.00000  103 1130 1760.42174    0.00000   100%   105 7026s\n",
      " 168419 62680    0.00000   47 3032 1760.42174    0.00000   100%   106 7034s\n",
      " 168928 62897    0.00000   63 2967 1760.42174    0.00000   100%   106 7042s\n",
      " 169674 63315    0.00000   53  663 1760.42174    0.00000   100%   106 7049s\n",
      " 169991 63415    0.00000   63 1112 1760.42174    0.00000   100%   106 7061s\n",
      " 170228 63426 infeasible   92      1760.42174    0.00000   100%   106 7066s\n",
      " 170437 63427 infeasible   78      1760.42174    0.00000   100%   106 7075s\n",
      " 170954 63649    0.00000   63  952 1760.42174    0.00000   100%   107 7084s\n",
      " 171475 63994 infeasible   76      1760.42174    0.00000   100%   107 7093s\n",
      " 171521 63989    0.00000   43 1101 1760.42174    0.00000   100%   107 7101s\n",
      " 171881 64179    0.00000   63 2003 1760.42174    0.00000   100%   107 7111s\n",
      " 172319 64408    0.00000   43 2306 1760.42174    0.00000   100%   107 7119s\n",
      " 172822 64674    0.00000   53  278 1760.42174    0.00000   100%   108 7126s\n",
      " 173079 64796    0.00000   53  927 1760.42174    0.00000   100%   108 7133s\n",
      " 173401 64909    0.00000   43 2919 1760.42174    0.00000   100%   108 7142s\n",
      " 174361 65299    0.20425   90 1560 1760.42174    0.00000   100%   109 7150s\n",
      " 175471 65859 infeasible   54      1760.42174    0.00000   100%   108 7156s\n",
      " 175927 66007 infeasible   55      1760.42174    0.00000   100%   108 7162s\n",
      " 176569 66273 infeasible   56      1760.42174    0.00000   100%   108 7167s\n",
      " 177063 66501 infeasible   43      1760.42174    0.00000   100%   108 7177s\n",
      " 178048 66940 infeasible   53      1760.42174    0.00000   100%   108 7194s\n",
      " 178330 66977    0.00000   33 1126 1760.42174    0.00000   100%   109 7207s\n",
      " 178404 67007    0.00000   43 2552 1760.42174    0.00000   100%   109 7232s\n",
      " 178504 67051 infeasible   52      1760.42174    0.00000   100%   109 7266s\n",
      " 178560 67077    0.00000   72 1358 1760.42174    0.00000   100%   110 7287s\n",
      " 178892 67261    0.00000   38 2522 1760.42174    0.00000   100%   110 7302s\n",
      " 179004 67302    0.00000   43 2914 1760.42174    0.00000   100%   110 7355s\n",
      " 179142 67387    0.00000   53 2139 1760.42174    0.00000   100%   111 7400s\n",
      " 179199 67435    0.00000   63 2668 1760.42174    0.00000   100%   111 7438s\n",
      " 179269 67485    0.00000   73 1840 1760.42174    0.00000   100%   111 7444s\n",
      " 179480 67608 infeasible   58      1760.42174    0.00000   100%   111 7453s\n",
      " 179723 67746    0.00000   89 1727 1760.42174    0.00000   100%   111 7462s\n",
      " 180022 67947    0.00000   97 1847 1760.42174    0.00000   100%   111 7504s\n",
      " 180094 67991 infeasible  124      1760.42174    0.00000   100%   111 7516s\n",
      " 180320 68136    0.00000   63  899 1760.42174    0.00000   100%   112 7528s\n",
      " 180495 68252    0.00000   83  889 1760.42174    0.00000   100%   112 7537s\n",
      " 180937 68528    0.00000  103 1019 1760.42174    0.00000   100%   112 7546s\n",
      " 181312 68754 infeasible  133      1760.42174    0.00000   100%   112 7554s\n",
      " 181480 68809    0.07742   77  954 1760.42174    0.00000   100%   112 7562s\n",
      " 181720 68932   26.24144   85 3185 1760.42174    0.00000   100%   112 8099s\n",
      " 181817 68969    2.97907   76 1226 1760.42174    0.00000   100%   112 8107s\n",
      " 182006 69038    0.08753   71 1549 1760.42174    0.00000   100%   112 8119s\n",
      " 182234 69083 infeasible  123      1760.42174    0.00000   100%   113 8128s\n",
      " 182419 69165    0.00000   23  212 1760.42174    0.00000   100%   113 8136s\n",
      " 182545 69250 infeasible   41      1760.42174    0.00000   100%   113 8145s\n",
      " 182633 69294    0.00000   50 2603 1760.42174    0.00000   100%   113 8157s\n",
      " 182809 69372    0.00000   53 2263 1760.42174    0.00000   100%   113 8167s\n",
      " 183015 69462    0.00000   63 1652 1760.42174    0.00000   100%   114 8178s\n",
      " 183292 69588 infeasible  133      1760.42174    0.00000   100%   114 8186s\n",
      " 183544 69641 infeasible   43      1760.42174    0.00000   100%   114 8197s\n",
      " 183960 69765 infeasible   41      1760.42174    0.00000   100%   114 8208s\n",
      " 184410 69851    0.00000   93 2337 1760.42174    0.00000   100%   115 8213s\n",
      " 184760 69886 infeasible   59      1760.42174    0.00000   100%   115 8216s\n",
      " 185073 69854   18.07484   53 1624 1760.42174    0.00000   100%   115 8224s\n",
      " 186337 70355    4.16277   56 1558 1760.42174    0.00000   100%   114 8229s\n",
      " 187035 70570 infeasible   80      1760.42174    0.00000   100%   114 8232s\n",
      " 187168 70544 infeasible   69      1760.42174    0.00000   100%   114 8240s\n",
      " 187619 70669    2.09929   84 2129 1760.42174    0.00000   100%   114 8246s\n",
      " 188127 70785 infeasible   76      1760.42174    0.00000   100%   114 8253s\n",
      " 188785 71049    0.00000   51 3231 1760.42174    0.00000   100%   114 8261s\n",
      " 188942 71042 infeasible   73      1760.42174    0.00000   100%   114 8270s\n",
      " 189982 71138  119.92265   33 1334 1760.42174    0.00000   100%   114 8278s\n",
      " 190891 71220 1342.20000  798   62 1760.42174    0.00000   100%   113 8286s\n",
      "*190961 69901             858    1400.5565217    0.00000   100%   113 8286s\n",
      " 191382 70057    0.03890   73  856 1400.55652    0.00000   100%   113 8295s\n",
      " 191897 70147    1.23338   98  630 1400.55652    0.00000   100%   113 8302s\n",
      " 192356 70334 infeasible   46      1400.55652    0.00000   100%   113 8309s\n",
      " 192580 70369    0.20425   53 2660 1400.55652    0.00000   100%   113 8314s\n",
      " 192766 70378 infeasible   53      1400.55652    0.00000   100%   114 8324s\n",
      " 193317 70481    0.00000   63 1219 1400.55652    0.00000   100%   114 8328s\n",
      " 193609 70504 infeasible   77      1400.55652    0.00000   100%   114 8334s\n",
      " 193891 70525 infeasible   46      1400.55652    0.00000   100%   114 8338s\n",
      " 194474 70658 infeasible   76      1400.55652    0.00000   100%   114 8344s\n",
      " 195348 70923    0.00000  127  663 1400.55652    0.00000   100%   113 8351s\n",
      " 196645 71243 infeasible  431      1400.55652    0.00000   100%   113 8357s\n",
      " 198130 71919 infeasible   71      1400.55652    0.00000   100%   112 8361s\n",
      " 198860 72138 infeasible   86      1400.55652    0.00000   100%   112 8365s\n",
      " 199851 72516  449.79766  413 1667 1400.55652    0.00000   100%   112 8370s\n",
      " 201338 73032 infeasible  254      1400.55652    0.00000   100%   112 8378s\n",
      " 202087 73316 infeasible   95      1400.55652    0.00000   100%   111 8382s\n",
      " 202567 73482    0.01945  106 1113 1400.55652    0.00000   100%   111 8386s\n",
      " 202753 73540    0.00000   77 1547 1400.55652    0.00000   100%   111 8394s\n",
      " 203103 73631 infeasible   63      1400.55652    0.00000   100%   111 8399s\n",
      " 203153 73644    0.00000   63 2456 1400.55652    0.00000   100%   112 8405s\n",
      " 203782 73872    0.01945   43 2961 1400.55652    0.00000   100%   112 8413s\n",
      " 204541 74030  105.21296   72 2287 1400.55652    0.00000   100%   111 8419s\n",
      " 205049 74175 infeasible   83      1400.55652    0.00000   100%   111 8424s\n",
      " 205608 74320    0.11185   99 1640 1400.55652    0.00000   100%   111 8431s\n",
      " 206272 74548    0.30151  133 1592 1400.55652    0.00000   100%   111 8435s\n",
      " 207011 74714 infeasible   74      1400.55652    0.00000   100%   111 8444s\n",
      " 207787 74973    0.00000   43 1128 1400.55652    0.00000   100%   111 8448s\n",
      " 208273 75210    0.00000   35  913 1400.55652    0.00000   100%   111 8451s\n",
      " 208649 75257  174.46270  107 1335 1400.55652    0.00000   100%   111 8456s\n",
      " 209570 75454  412.19869  249 1900 1400.55652    0.00000   100%   111 8460s\n",
      " 211158 75827 infeasible  289      1400.55652    0.00000   100%   111 8470s\n",
      " 211641 75933    0.00000  123 1184 1400.55652    0.00000   100%   110 8477s\n",
      " 211705 75952    0.00000   73 1186 1400.55652    0.00000   100%   111 8482s\n",
      " 211771 75926    0.00000   23 1091 1400.55652    0.00000   100%   111 8486s\n",
      " 212005 76018    0.00000   52   93 1400.55652    0.00000   100%   111 8490s\n",
      " 212417 76102   75.42783   61 1599 1400.55652    0.00000   100%   111 8495s\n",
      " 213097 76407  338.33166  202 1617 1400.55652    0.00000   100%   111 8500s\n",
      " 213870 76775 infeasible   97      1400.55652    0.00000   100%   110 8508s\n",
      " 214234 76873  251.80974  155 1747 1400.55652    0.00000   100%   110 8514s\n",
      " 214740 77128  800.05366  441 1607 1400.55652    0.00000   100%   110 8520s\n",
      " 215144 77359 1060.30853  727 1351 1400.55652    0.00000   100%   110 8525s\n",
      " 215360 77484 1126.46538  830 1283 1400.55652    0.00000   100%   110 8531s\n",
      " 215692 77654    0.00000   62 1092 1400.55652    0.00000   100%   110 8536s\n",
      " 215914 77715    0.00000   66  722 1400.55652    0.00000   100%   110 8541s\n",
      " 216028 77763    0.00000   62  685 1400.55652    0.00000   100%   110 8545s\n",
      " 216211 77814    0.00000   64  670 1400.55652    0.00000   100%   110 8550s\n",
      " 216734 77861    0.00000   53  580 1400.55652    0.00000   100%   110 8561s\n",
      " 217122 77941    0.00000   63 1236 1400.55652    0.00000   100%   110 8566s\n",
      " 217665 78066    0.00000   73 1294 1400.55652    0.00000   100%   110 8575s\n",
      " 218634 78336    0.00000   63 1383 1400.55652    0.00000   100%   110 8583s\n",
      " 219098 78469 infeasible   53      1400.55652    0.00000   100%   110 8590s\n",
      " 219763 78717    0.00000   63  739 1400.55652    0.00000   100%   110 8598s\n",
      " 220448 78971    0.00000   85 1030 1400.55652    0.00000   100%   110 8603s\n",
      " 220715 79012 infeasible   83      1400.55652    0.00000   100%   110 8607s\n",
      " 220973 79076    3.43783  116  589 1400.55652    0.00000   100%   110 8611s\n",
      " 221262 79162    0.00000   33 2031 1400.55652    0.00000   100%   110 8617s\n",
      " 221584 79235    0.00000   33 2117 1400.55652    0.00000   100%   110 8623s\n",
      " 221806 79251    0.00000   53  340 1400.55652    0.00000   100%   110 8628s\n",
      " 222081 79283    0.00000   63 1189 1400.55652    0.00000   100%   110 8631s\n",
      " 222381 79341    0.00000   43 1643 1400.55652    0.00000   100%   110 8638s\n",
      " 222695 79416 infeasible   53      1400.55652    0.00000   100%   110 8642s\n",
      " 222861 79427    0.00000   63  748 1400.55652    0.00000   100%   110 8652s\n",
      " 223014 79446    0.07704   69 1617 1400.55652    0.00000   100%   110 8657s\n",
      " 223149 79466    0.00000   73  603 1400.55652    0.00000   100%   110 8661s\n",
      " 223404 79545    0.03852   53 1037 1400.55652    0.00000   100%   110 8669s\n",
      " 223583 79630    0.00000   53 1946 1400.55652    0.00000   100%   110 8675s\n",
      " 223912 79727    0.11671   69 1373 1400.55652    0.00000   100%   110 8681s\n",
      " 224148 79790    0.32972   74 1984 1400.55652    0.00000   100%   111 8686s\n",
      " 224690 79967    2.00300   53 1213 1400.55652    0.00000   100%   110 8692s\n",
      " 224813 80020    0.17334   43 3065 1400.55652    0.00000   100%   111 8698s\n",
      " 225045 80135 infeasible   40      1400.55652    0.00000   100%   111 8705s\n",
      " 225319 80281    0.00000   95 1007 1400.55652    0.00000   100%   111 8714s\n",
      " 225467 80369    0.00000  105 1007 1400.55652    0.00000   100%   111 8721s\n",
      " 225532 80407    0.00000  124  965 1400.55652    0.00000   100%   111 8726s\n",
      " 225611 80427    0.00000  144 1304 1400.55652    0.00000   100%   111 8733s\n",
      " 225889 80574    0.00000   93 1414 1400.55652    0.00000   100%   111 8738s\n",
      " 226025 80597    0.01926  123 1237 1400.55652    0.00000   100%   111 8743s\n",
      " 226171 80625    0.00000   63 1008 1400.55652    0.00000   100%   111 8751s\n",
      " 226399 80698 infeasible  112      1400.55652    0.00000   100%   111 8756s\n",
      " 226639 80817    0.00000   72 1633 1400.55652    0.00000   100%   112 8760s\n",
      " 227118 80935    0.03852   66 2146 1400.55652    0.00000   100%   112 8768s\n",
      " 227346 80999    0.00000   63  229 1400.55652    0.00000   100%   112 8773s\n",
      " 227466 81017    0.00000   74  694 1400.55652    0.00000   100%   112 8785s\n",
      " 227714 81109    0.01926   81 1779 1400.55652    0.00000   100%   112 8791s\n",
      " 227949 81217 infeasible  108      1400.55652    0.00000   100%   112 8799s\n",
      " 228672 81610    0.00000   73 1034 1400.55652    0.00000   100%   112 8806s\n",
      " 229130 81817    0.00000   58 1917 1400.55652    0.00000   100%   112 8810s\n",
      " 229277 81857 infeasible   66      1400.55652    0.00000   100%   112 8818s\n",
      " 229938 82041   11.78744  102 1596 1400.55652    0.00000   100%   112 8823s\n",
      " 230456 82230 infeasible   98      1400.55652    0.00000   100%   112 8827s\n",
      " 230591 82207 infeasible   85      1400.55652    0.00000   100%   112 8833s\n",
      " 230666 82130 infeasible   51      1400.55652    0.00000   100%   112 8835s\n",
      " 231047 82054 infeasible   65      1400.55652    0.00000   100%   112 8842s\n",
      " 231296 82075 infeasible   75      1400.55652    0.00000   100%   112 8847s\n",
      " 231545 82081 infeasible   42      1400.55652    0.00000   100%   112 8854s\n",
      " 231954 82246    1.94522   54 1985 1400.55652    0.00000   100%   112 8859s\n",
      " 232474 82471    1.94522   61 1298 1400.55652    0.00000   100%   111 8867s\n",
      " 232843 82608 infeasible   52      1400.55652    0.00000   100%   112 8872s\n",
      " 232965 82645    0.00000   57  954 1400.55652    0.00000   100%   112 8881s\n",
      " 233134 82678    5.47935   43 3480 1400.55652    0.00000   100%   112 8889s\n",
      " 233596 82769    0.00000   73 2785 1400.55652    0.00000   100%   112 8899s\n",
      " 233805 82859    0.00000   83 3259 1400.55652    0.00000   100%   112 8909s\n",
      " 234010 82922 infeasible  134      1400.55652    0.00000   100%   112 8920s\n",
      " 234110 82965    0.01945   47 1646 1400.55652    0.00000   100%   112 8926s\n",
      " 234416 83180 infeasible   62      1400.55652    0.00000   100%   112 8940s\n",
      " 235403 83754 infeasible   51      1400.55652    0.00000   100%   112 8958s\n",
      " 236025 84228    0.01945   40 2818 1400.55652    0.00000   100%   112 8966s\n",
      " 236144 84240    0.93370   39 2581 1400.55652    0.00000   100%   112 8976s\n",
      " 236375 84321    0.00000   43 2100 1400.55652    0.00000   100%   112 8986s\n",
      " 237232 84661    4.04451  112  787 1400.55652    0.00000   100%   112 8996s\n",
      " 238023 84886    6.97197  174  693 1400.55652    0.00000   100%   112 9003s\n",
      " 238546 85047    0.01945   49 2809 1400.55652    0.00000   100%   112 9013s\n",
      " 239253 85290    0.00000   62 1613 1400.55652    0.00000   100%   112 9020s\n",
      " 239633 85409    0.00000   63 1558 1400.55652    0.00000   100%   112 9027s\n",
      " 240243 85642  628.66922  112 2709 1400.55652    0.00000   100%   112 9035s\n",
      " 241277 86054    0.01926   31 2911 1400.55652    0.00000   100%   112 9042s\n",
      " 242223 86514    3.77488  106 1075 1400.55652    0.00000   100%   112 9053s\n",
      " 243401 86934 infeasible  217      1400.55652    0.00000   100%   111 9061s\n",
      " 244339 87136    0.00000   75  508 1400.55652    0.00000   100%   111 9067s\n",
      " 245496 87445    1.17686   33 2907 1400.55652    0.00000   100%   111 9073s\n",
      " 245867 87543 infeasible   53      1400.55652    0.00000   100%   111 9079s\n",
      " 246112 87625 infeasible   42      1400.55652    0.00000   100%   111 9089s\n",
      " 246795 87842    0.00000   63 1206 1400.55652    0.00000   100%   111 9098s\n",
      " 246923 87839    0.00000   23  581 1400.55652    0.00000   100%   111 9105s\n",
      " 247199 88012 infeasible   34      1400.55652    0.00000   100%   111 9110s\n",
      " 247319 88070    0.01926   50 1526 1400.55652    0.00000   100%   111 9121s\n",
      " 247465 88089    6.12705   57 2002 1400.55652    0.00000   100%   111 9129s\n",
      " 247609 88179 infeasible   60      1400.55652    0.00000   100%   111 9136s\n",
      " 247745 88249    0.00000   69 2470 1400.55652    0.00000   100%   111 9143s\n",
      " 247959 88341    0.00000   43 1057 1400.55652    0.00000   100%   111 9153s\n",
      " 248156 88437    0.09649   53 1784 1400.55652    0.00000   100%   111 9163s\n",
      " 248355 88519    2.04209   63 3253 1400.55652    0.00000   100%   112 9168s\n",
      " 248521 88591    0.00000   43 2522 1400.55652    0.00000   100%   112 9174s\n",
      " 248716 88668    2.04152   79 1328 1400.55652    0.00000   100%   112 9181s\n",
      " 248955 88792 infeasible   49      1400.55652    0.00000   100%   112 9190s\n",
      " 249174 88875    0.00000   63 1466 1400.55652    0.00000   100%   112 9200s\n",
      " 249313 88925 infeasible   73      1400.55652    0.00000   100%   112 9208s\n",
      " 249484 88960    0.00000   83 2448 1400.55652    0.00000   100%   112 9222s\n",
      " 249935 89087   27.12437   58 1730 1400.55652    0.00000   100%   112 9229s\n",
      " 250275 89205  290.73123   59 2423 1400.55652    0.00000   100%   112 9236s\n",
      " 251270 89617    0.00000   83 1334 1400.55652    0.00000   100%   112 9246s\n",
      " 252447 89948    1.94522   88 2025 1400.55652    0.00000   100%   112 9252s\n",
      " 253264 90323  347.76349   58 2337 1400.55652    0.00000   100%   112 9258s\n",
      " 253812 90643   53.26978   61 1664 1400.55652    0.00000   100%   112 9267s\n",
      " 255496 91460   53.26978   65 1656 1400.55652    0.00000   100%   111 9275s\n",
      " 256927 92145   54.29102   74 1638 1400.55652    0.00000   100%   111 9288s\n",
      " 257792 92453 infeasible  172      1400.55652    0.00000   100%   111 9296s\n",
      " 259151 92738  390.18143  599 1180 1400.55652    0.00000   100%   110 9302s\n",
      " 260054 92823  606.55769  839  932 1400.55652    0.00000   100%   110 9311s\n",
      " 261334 93092  318.38750   96 2293 1400.55652    0.00000   100%   110 9317s\n",
      " 262063 93311  148.24502   84 2403 1400.55652    0.00000   100%   110 9338s\n",
      " 262628 93605  388.96567  254 2143 1400.55652    0.00000   100%   109 9345s\n",
      " 262984 93679 infeasible   62      1400.55652    0.00000   100%   109 9350s\n",
      " 263674 93979    0.00000   84  917 1400.55652    0.00000   100%   109 9360s\n",
      " 264101 94131    0.00000   93  807 1400.55652    0.00000   100%   109 9365s\n",
      " 264545 94379    0.00000  113  998 1400.55652    0.00000   100%   109 9370s\n",
      " 264950 94537 infeasible   79      1400.55652    0.00000   100%   109 9652s\n",
      " 265351 94844  351.82782   56 2325 1400.55652    0.00000   100%   109 9657s\n",
      " 265476 94875  178.60620   62 1544 1400.55652    0.00000   100%   109 9662s\n",
      " 265631 94899  354.93223   77 2323 1400.55652    0.00000   100%   109 9669s\n",
      " 266133 95115    0.00000   43 2027 1400.55652    0.00000   100%   109 9682s\n",
      " 266367 95176    0.03852   53 1757 1400.55652    0.00000   100%   109 9689s\n",
      " 266498 95169 infeasible   53      1400.55652    0.00000   100%   109 9694s\n",
      " 266644 95174 infeasible   85      1400.55652    0.00000   100%   109 9702s\n",
      " 266887 95231 infeasible   41      1400.55652    0.00000   100%   109 9708s\n",
      " 267187 95418 infeasible   50      1400.55652    0.00000   100%   109 9712s\n",
      " 267315 95412    0.00000   46  941 1400.55652    0.00000   100%   109 9721s\n",
      " 267885 95608 infeasible   31      1400.55652    0.00000   100%   109 9731s\n",
      " 268478 95692    2.06077   78 1769 1400.55652    0.00000   100%   109 9738s\n",
      " 269325 95854    0.01945   51  966 1400.55652    0.00000   100%   109 9745s\n",
      " 270169 96055 infeasible   55      1400.55652    0.00000   100%   109 9756s\n",
      " 270282 96060    2.21485   69 1276 1400.55652    0.00000   100%   109 9763s\n",
      " 271423 96525    2.84400   97 2140 1400.55652    0.00000   100%   109 9768s\n",
      " 271806 96669 infeasible  109      1400.55652    0.00000   100%   109 9777s\n",
      " 271979 96750 infeasible   43      1400.55652    0.00000   100%   109 9794s\n",
      " 272135 96817    0.00000   83 1343 1400.55652    0.00000   100%   109 9800s\n",
      " 272279 96907    0.01945   98 1743 1400.55652    0.00000   100%   109 9809s\n",
      " 272457 97000    1.96467  149 1778 1400.55652    0.00000   100%   109 9816s\n",
      " 272666 97069   47.73418  104 2479 1400.55652    0.00000   100%   109 9821s\n",
      " 272885 97163  133.47928  164 2369 1400.55652    0.00000   100%   109 9833s\n",
      " 273218 97274    0.05836   40 2674 1400.55652    0.00000   100%   109 9841s\n",
      " 273321 97317    2.06193   55 2655 1400.55652    0.00000   100%   109 9848s\n",
      " 273401 97316    0.00000   53  971 1400.55652    0.00000   100%   109 9857s\n",
      " 273568 97350    0.28779   44 2098 1400.55652    0.00000   100%   109 9862s\n",
      " 273908 97431    0.01945   30 3372 1400.55652    0.00000   100%   109 9869s\n",
      " 274248 97587 infeasible   74      1400.55652    0.00000   100%   109 9880s\n",
      " 274329 97583    0.00000   33 2806 1400.55652    0.00000   100%   109 9886s\n",
      " 274488 97580    0.00000   31 3209 1400.55652    0.00000   100%   110 9894s\n",
      " 275053 97701    0.00000   33 1596 1400.55652    0.00000   100%   109 9903s\n",
      " 275494 97883    0.01926   53 1874 1400.55652    0.00000   100%   109 9910s\n",
      " 275837 98048    0.00000   43 2632 1400.55652    0.00000   100%   109 9918s\n",
      " 276425 98352    0.00000   48  442 1400.55652    0.00000   100%   109 9929s\n",
      " 276589 98420    0.00000   33 1443 1400.55652    0.00000   100%   110 9941s\n",
      " 276791 98509    9.93033  130 1454 1400.55652    0.00000   100%   110 9950s\n",
      " 276980 98571    0.03890   92 2263 1400.55652    0.00000   100%   110 9965s\n",
      " 277288 98726    0.01926   52 1184 1400.55652    0.00000   100%   110 9979s\n",
      " 277424 98796    0.00000   43 2197 1400.55652    0.00000   100%   110 9990s\n",
      " 277554 98865    0.00000   53 2440 1400.55652    0.00000   100%   110 10009s\n",
      " 277629 98888    0.00000   54 2440 1400.55652    0.00000   100%   110 10021s\n",
      " 278100 99164    0.00000   63 2863 1400.55652    0.00000   100%   110 10030s\n",
      " 278458 99420    0.20425   43 2673 1400.55652    0.00000   100%   110 10043s\n",
      " 278708 99597    0.00000   63 1754 1400.55652    0.00000   100%   110 10062s\n",
      " 278804 99661    0.00000   53 1087 1400.55652    0.00000   100%   111 10081s\n",
      " 278869 99699    0.85590   64 3316 1400.55652    0.00000   100%   111 10092s\n",
      " 279031 99775    1.94522   63 2573 1400.55652    0.00000   100%   111 10103s\n",
      " 279459 100037    1.94522   81 2679 1400.55652    0.00000   100%   111 10554s\n",
      " 279847 100281    0.00000   53 3605 1400.55652    0.00000   100%   111 10564s\n",
      " 279940 100326    0.42795   82 3628 1400.55652    0.00000   100%   111 10575s\n",
      " 280057 100406    3.22906  112 3604 1400.55652    0.00000   100%   111 10586s\n",
      " 280184 100436    7.54744  141 3599 1400.55652    0.00000   100%   111 10599s\n",
      " 280285 100465    0.00000   53 1886 1400.55652    0.00000   100%   111 10611s\n",
      " 280423 100511    0.01945   78 4133 1400.55652    0.00000   100%   111 10628s\n",
      " 280686 100608    0.01945  107 3779 1400.55652    0.00000   100%   112 10641s\n",
      " 281516 101179    3.90989  147 3762 1400.55652    0.00000   100%   112 10652s\n",
      " 281911 101362    0.00000   73  951 1400.55652    0.00000   100%   112 10663s\n",
      " 282469 101686 infeasible   87      1400.55652    0.00000   100%   112 10676s\n",
      " 283271 102153 infeasible   63      1400.55652    0.00000   100%   112 10692s\n",
      " 283762 102440 infeasible   73      1400.55652    0.00000   100%   112 10708s\n",
      " 284875 102938    0.00000   63 3649 1400.55652    0.00000   100%   112 10718s\n",
      " 285568 103303 infeasible   63      1400.55652    0.00000   100%   112 10733s\n",
      " 285887 103422    3.96824   63 3366 1400.55652    0.00000   100%   112 10743s\n",
      " 286412 103692 infeasible   68      1400.55652    0.00000   100%   113 10759s\n",
      " 286840 103927    0.00000   73 3229 1400.55652    0.00000   100%   113 10772s\n",
      " 287749 104427    0.00000   53 3001 1400.55652    0.00000   100%   113 10782s\n",
      " 288631 104945    7.84857  101 3512 1400.55652    0.00000   100%   112 10792s\n",
      " 290301 105754 infeasible   71      1400.55652    0.00000   100%   112 10798s\n",
      " 290767 105856 infeasible   75      1400.55652    0.00000   100%   112 10807s\n",
      " 291066 105942    0.03890   71 3887 1400.55652    0.00000   100%   112 10821s\n",
      " 291551 106139    0.01945   71 2470 1400.55652    0.00000   100%   112 10835s\n",
      " 291805 106215    0.01945   55 3604 1400.55652    0.00000   100%   112 10843s\n",
      " 292051 106329    0.00000   68 3114 1400.55652    0.00000   100%   113 10862s\n",
      " 292301 106466    0.00000   48 4375 1400.55652    0.00000   100%   113 10873s\n",
      " 292676 106624    0.03890   72 2910 1400.55652    0.00000   100%   113 10886s\n",
      " 294087 107324    0.00000   63 2181 1400.55652    0.00000   100%   113 10896s\n",
      " 294601 107614 infeasible   62      1400.55652    0.00000   100%   113 10911s\n",
      " 295016 107810   15.04626  123 3054 1400.55652    0.00000   100%   113 10919s\n",
      " 295724 108179    0.00000   65 2381 1400.55652    0.00000   100%   113 10929s\n",
      " 296763 108807 infeasible   52      1400.55652    0.00000   100%   113 10937s\n",
      " 297892 109302 infeasible   67      1400.55652    0.00000   100%   113 10943s\n",
      " 298039 109379    0.13617   56 3628 1400.55652    0.00000   100%   113 10950s\n",
      " 298437 109641   16.41336  102 3104 1400.55652    0.00000   100%   113 10958s\n",
      " 299115 110105   10.38091  160 3113 1400.55652    0.00000   100%   113 10966s\n",
      " 299851 110590 infeasible   54      1400.55652    0.00000   100%   113 10974s\n",
      " 300594 111121    0.00000   53 3896 1400.55652    0.00000   100%   113 10981s\n",
      " 300747 111162 infeasible   94      1400.55652    0.00000   100%   113 10991s\n",
      " 301268 111418 infeasible   59      1400.55652    0.00000   100%   113 11000s\n",
      " 301857 111734 infeasible   66      1400.55652    0.00000   100%   113 11010s\n",
      " 302082 111843    7.78087   85 3402 1400.55652    0.00000   100%   113 11023s\n",
      " 302756 112221    0.00000   53 2680 1400.55652    0.00000   100%   113 11033s\n",
      " 303211 112474    1.94522   61 3481 1400.55652    0.00000   100%   113 11039s\n",
      " 303369 112507    0.01945   47 2339 1400.55652    0.00000   100%   113 11046s\n",
      " 303825 112664 infeasible   57      1400.55652    0.00000   100%   113 11053s\n",
      " 304026 112724 infeasible   60      1400.55652    0.00000   100%   114 11064s\n",
      " 304630 112989    0.00000   43 1891 1400.55652    0.00000   100%   114 11079s\n",
      " 304678 113001    1.94522   53 2710 1400.55652    0.00000   100%   114 11088s\n",
      " 304965 113167 infeasible  165      1400.55652    0.00000   100%   114 11098s\n",
      " 305473 113383    0.00000   53  868 1400.55652    0.00000   100%   114 11109s\n",
      " 306191 113765    0.00000   53 3709 1400.55652    0.00000   100%   114 11119s\n",
      " 306512 113973 infeasible   56      1400.55652    0.00000   100%   114 11126s\n",
      " 306907 114185    0.00000   66 3025 1400.55652    0.00000   100%   114 11137s\n",
      " 307726 114529    3.89043   64 2996 1400.55652    0.00000   100%   114 11145s\n",
      " 308331 114813    0.03890   46 3900 1400.55652    0.00000   100%   114 11154s\n",
      " 309342 115265    0.00000   63  765 1400.55652    0.00000   100%   114 11163s\n",
      " 310268 115789    2.56769   43 2258 1400.55652    0.00000   100%   114 11186s\n",
      " 311286 116230 infeasible   52      1400.55652    0.00000   100%   114 11192s\n",
      " 311543 116318    2.02303   59 4385 1400.55652    0.00000   100%   114 11203s\n",
      " 312198 116531    0.00000   53 1578 1400.55652    0.00000   100%   114 11213s\n",
      " 313244 116902    0.00000   46  901 1400.55652    0.00000   100%   114 11219s\n",
      " 313751 117098    0.03852   41 2740 1400.55652    0.00000   100%   114 11227s\n",
      " 313900 117138 infeasible   47      1400.55652    0.00000   100%   114 11235s\n",
      " 314554 117338    0.00000   70  576 1400.55652    0.00000   100%   114 11243s\n",
      " 315082 117574    0.00000   39 2349 1400.55652    0.00000   100%   114 11250s\n",
      " 315428 117662 infeasible   75      1400.55652    0.00000   100%   114 11259s\n",
      " 315928 117822 infeasible   66      1400.55652    0.00000   100%   114 11266s\n",
      " 316158 117837 infeasible   67      1400.55652    0.00000   100%   114 11276s\n",
      " 316594 117997 infeasible   50      1400.55652    0.00000   100%   114 11283s\n",
      " 317263 118201 infeasible   45      1400.55652    0.00000   100%   114 11295s\n",
      " 317804 118478    0.01945   43 2801 1400.55652    0.00000   100%   114 11308s\n",
      " 318001 118570    5.08674   75 3144 1400.55652    0.00000   100%   114 11319s\n",
      " 318430 118676    0.00000   48 1313 1400.55652    0.00000   100%   115 11328s\n",
      " 318652 118755    3.00931   49  677 1400.55652    0.00000   100%   115 11338s\n",
      " 318845 118833    0.00000   47 4298 1400.55652    0.00000   100%   115 11346s\n",
      " 318991 118876    0.01945   55 4334 1400.55652    0.00000   100%   115 11357s\n",
      " 319513 119038 infeasible   84      1400.55652    0.00000   100%   115 11366s\n",
      " 321029 119481  910.96110  762 1281 1400.55652    0.00000   100%   114 11383s\n",
      " 322881 120238    0.00000   63 1977 1400.55652    0.00000   100%   114 11395s\n",
      " 323723 120515   77.76979  180 2149 1400.55652    0.00000   100%   114 11401s\n",
      " 324554 120809 infeasible  166      1400.55652    0.00000   100%   114 11408s\n",
      " 326096 121228  321.41800  338 2000 1400.55652    0.00000   100%   113 11414s\n",
      " 327084 121506 infeasible  467      1400.55652    0.00000   100%   113 11419s\n",
      " 328347 121935 infeasible  183      1400.55652    0.00000   100%   113 11426s\n",
      " 329796 122567   89.32438  157 2117 1400.55652    0.00000   100%   113 11431s\n",
      " 331009 123029 infeasible  176      1400.55652    0.00000   100%   112 11439s\n",
      " 331585 123282    0.00000   63 2743 1400.55652    0.00000   100%   112 11446s\n",
      " 332553 123662    0.00000   73 3018 1400.55652    0.00000   100%   112 11455s\n",
      " 332953 123823    0.00000   83 3040 1400.55652    0.00000   100%   112 11460s\n",
      " 333328 124006    0.07781  131 3148 1400.55652    0.00000   100%   112 11468s\n",
      " 333510 124109 infeasible  221      1400.55652    0.00000   100%   112 11474s\n",
      " 333569 124121    0.00000   93 1875 1400.55652    0.00000   100%   112 11481s\n",
      " 333832 124256    0.00000   63 2167 1400.55652    0.00000   100%   112 11487s\n",
      " 333904 124290    1.94522   78 2720 1400.55652    0.00000   100%   112 11492s\n",
      " 333959 124300    0.00000   53 1477 1400.55652    0.00000   100%   112 11497s\n",
      " 334027 124310 infeasible   53      1400.55652    0.00000   100%   113 11503s\n",
      " 334125 124343    0.01945   56 2769 1400.55652    0.00000   100%   113 11507s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 19\n",
      "  MIR: 37\n"
     ]
    }
   ],
   "source": [
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Outputs\n",
    "\n",
    "While the verbose output of Gurobi confirms that the optimizer ran successfully, I confirm as much below via a call to JuMP.  As expected, we see that the optimizer ended once it reached its time limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TIME_LIMIT::TerminationStatusCode = 12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termination_status(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now pull the various optimized outputs of the function.  $L_t$ gives the loss values at each leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-dimensional DenseAxisArray{Float64,1,...} with index sets:\n",
       "    Dimension 1, [4, 5, 6, 7]\n",
       "And data, a 4-element Array{Float64,1}:\n",
       "  -0.0\n",
       " 563.0\n",
       "  -0.0\n",
       " 156.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_{j,t}$ gives the feature $j$ used to apply a split at node $t$, and $b_t$ gives the split-point value of variable $j$ at node $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36×3 Array{Float64,2}:\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       "  1.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       "  ⋮              \n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0\n",
       " -0.0  -0.0  -0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-dimensional DenseAxisArray{Float64,1,...} with index sets:\n",
       "    Dimension 1, [1, 2, 3]\n",
       "And data, a 3-element Array{Float64,1}:\n",
       " 0.20999999999999852\n",
       " 0.0                \n",
       " 0.0                "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N_t$ gives the total number of $x_i$ input points assigned to leaf node $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-dimensional DenseAxisArray{Float64,1,...} with index sets:\n",
       "    Dimension 1, [4, 5, 6, 7]\n",
       "And data, a 4-element Array{Float64,1}:\n",
       "   -0.0\n",
       " 1557.0\n",
       "   -0.0\n",
       "  680.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(N_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we see the values for $N_{k,t}$, which stores the total number of inputs with label $k$ in leaf node $t$, and $c_{k,t}$, which gives the prediction $k$ in leaf node $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-dimensional DenseAxisArray{Float64,2,...} with index sets:\n",
       "    Dimension 1, 1:2\n",
       "    Dimension 2, [4, 5, 6, 7]\n",
       "And data, a 2×4 Array{Float64,2}:\n",
       "  0.0  994.0   0.0  156.0\n",
       " -0.0  563.0  -0.0  524.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(N_kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-dimensional DenseAxisArray{Float64,2,...} with index sets:\n",
       "    Dimension 1, 1:2\n",
       "    Dimension 2, [4, 5, 6, 7]\n",
       "And data, a 2×4 Array{Float64,2}:\n",
       " -0.0   1.0  -0.0  0.0\n",
       " -0.0  -0.0  -0.0  1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(c_kt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Model Performance\n",
    "\n",
    "With the model now optimized, I will use the variable outputs from Gurobi via the JuMP API to determine how well the model performs.  To do so, I first establish a set of helper functions.  Firstly, I will extract the label predictions for each leaf node $t_l$, then build a function that will test whether a given $x_i$ input fits into a given leaf node, and lastly, build an aggregate function that iterates over each leaf node and attempts to fit every point into a leaf node until a match is found.  This final function will output a total accuracy percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictTestPoints (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function labelLeafNodePredictions(N_kt)\n",
    "    #extract dimensions of N_kt array\n",
    "    rows = axes(N_kt)[1]\n",
    "    cols = axes(N_kt)[2]\n",
    "    \n",
    "    #initialize empty array to store label of prediction at each leaf node\n",
    "    #note that here we re-index leaf nodes such that the first leaf node is index 1\n",
    "    prediction = zeros(Int8, length(cols))\n",
    "    #prediction_index = cols .- (length(cols) - 1)\n",
    "    #iterate over each row in N_kt, saving max value\n",
    "    for c in cols\n",
    "        current_max = 0\n",
    "        current_prediction = 0\n",
    "        for r in rows\n",
    "            if value(N_kt[r,c]) > current_max\n",
    "                current_max = value(N_kt[r,c])\n",
    "                current_prediction = r\n",
    "            end\n",
    "        end\n",
    "        #push best prediction to output array\n",
    "        prediction[c- (length(cols) - 1)] = current_prediction\n",
    "    end\n",
    "    return prediction\n",
    "end\n",
    "\n",
    "function checkTreePoint(left_turns, right_turns, feature_row)\n",
    "    #check if left turns are correct for leaf node\n",
    "    for node in left_turns\n",
    "        if transpose(value.(a[:,node])) * feature_row < value(b[node])\n",
    "            continue\n",
    "        else\n",
    "            return false\n",
    "        end\n",
    "    end\n",
    "    #check if right turns are correct for leaf node\n",
    "    for node in right_turns\n",
    "        if transpose(value.(a[:,node])) * feature_row >= value(b[node])\n",
    "            continue\n",
    "        else\n",
    "            return false\n",
    "        end            \n",
    "    end\n",
    "    return true\n",
    "end\n",
    "\n",
    "function predictTestPoints(test_features, test_labels)\n",
    "    #ext variable\n",
    "    correct_predictions = length(test_labels)\n",
    "    \n",
    "    #copy test labels\n",
    "    lbls = copy(test_labels)\n",
    "    \n",
    "    #extract prediction from each leaf node\n",
    "    leaf_predictions = labelLeafNodePredictions(N_kt)\n",
    "    \n",
    "    #iterate over leaf nodes\n",
    "    for (leaf_index, leaf_value) in enumerate(t_l)\n",
    "        left_turns = A_left[leaf_value]\n",
    "        right_turns = A_right[leaf_value]\n",
    "        #skip empty leaves\n",
    "        if leaf_predictions[leaf_index] == 0\n",
    "            #println(\"no predictions at node \", leaf_value)\n",
    "            continue\n",
    "        end\n",
    "        for (label_index, label_value) in enumerate(lbls)\n",
    "            if label_value != leaf_predictions[leaf_index]\n",
    "                #println(\"skipping row - not matched to prediction of node\")\n",
    "                continue\n",
    "            end\n",
    "            if label_value == 0\n",
    "                println(\"skipping row - already correctly placed\")\n",
    "                continue\n",
    "            end       \n",
    "            #println(\"prediction at node \", leaf_value, \" is \", leaf_predictions[leaf_index])\n",
    "            #println(\"left ancestors are \", left_turns, \" ,right ancestors are \", right_turns)\n",
    "            if checkTreePoint(left_turns, right_turns, test_features[label_index,:])\n",
    "                lbls[label_index] = 0\n",
    "                #println(\"found one!\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    errors = correct_predictions - countmap(lbls)[0]\n",
    "    return 1 - (errors/correct_predictions)\n",
    "end\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these scoring functions in place, I can score the model's performance against the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785873938310236"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictTestPoints(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.694473409801877"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictTestPoints(test_features, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
